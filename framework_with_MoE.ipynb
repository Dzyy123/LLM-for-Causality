{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a383715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import math\n",
    "import re\n",
    "\n",
    "client = openai.OpenAI(\n",
    "    api_key=\"sk-JBfp0POD11gasNLNn1uTiQ\",  \n",
    "    base_url=\"https://llmapi.paratera.com/v1/\"  # 建议带上 https://\n",
    ")\n",
    "\n",
    "# === 工具函数 ===\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "def parse_probabilities(llm_output: str):\n",
    "    \"\"\"\n",
    "    从 LLM 文本输出中提取概率。\n",
    "    比如：\n",
    "    P(yes) = 0.0  \n",
    "    P(no) = 1.0\n",
    "    \"\"\"\n",
    "    matches = re.findall(r\"([0-9]*\\.?[0-9]+)\", llm_output)\n",
    "    if len(matches) >= 2:\n",
    "        p1, p2 = float(matches[0]), float(matches[1])\n",
    "        total = p1 + p2\n",
    "        if total == 0:\n",
    "            return 0.5, 0.5\n",
    "        return p1 / total, p2 / total\n",
    "    return 0.5, 0.5  # fallback\n",
    "\n",
    "def parse_logits(llm_output: str):\n",
    "    matches = re.findall(r\"([-]?[0-9]*\\.?[0-9]+)\", llm_output)\n",
    "    if len(matches) >= 2:\n",
    "        l1, l2 = float(matches[0]), float(matches[1])\n",
    "        if not math.isclose(l1 + l2, 0):\n",
    "            avg = (l1 - l2) / 2\n",
    "            l1, l2 = avg, -avg\n",
    "        return l1, l2\n",
    "    return 0.0, 0.0\n",
    "\n",
    "def llm_judge_openai(prompt, x1, x2, method='frequency', n_sample=10):\n",
    "    \"\"\"\n",
    "    使用 client.chat.completions.create\n",
    "    method: 'frequency' | 'probability' | 'logit'\n",
    "    返回: {\"label\": 1或0, \"prob\": 最大概率}\n",
    "    \"\"\"\n",
    "\n",
    "    if method == 'frequency':\n",
    "        votes = []\n",
    "        for _ in range(n_sample):\n",
    "            resp = client.chat.completions.create(\n",
    "                model=\"Qwen3-Next-80B-A3B-Thinking\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                max_tokens=50,\n",
    "                temperature=0.7,\n",
    "            )\n",
    "            text = resp.choices[0].message.content.strip()\n",
    "            votes.append(1 if text.lower().startswith(\"yes\") else 0)\n",
    "\n",
    "        p_yes = sum(votes) / len(votes)\n",
    "        p_no = 1 - p_yes\n",
    "        # 取最大标签与其概率（平局默认选 yes=>1）\n",
    "        if p_yes >= p_no:\n",
    "            return {\"label\": 1, \"prob\": p_yes}\n",
    "        else:\n",
    "            return {\"label\": 0, \"prob\": p_no}\n",
    "\n",
    "    elif method == 'probability':\n",
    "        resp = client.chat.completions.create(\n",
    "            model=\"Qwen3-Next-80B-A3B-Thinking\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=200,\n",
    "            temperature=0.7,\n",
    "        )\n",
    "        text = resp.choices[0].message.content.strip()\n",
    "        #print(\"LLM 原始输出：\\n\", text)  # 调试用\n",
    "\n",
    "        p_yes, p_no = parse_probabilities(text)\n",
    "        if p_yes >= p_no:\n",
    "            return {\"label\": 1, \"prob\": p_yes}\n",
    "        else:\n",
    "            return {\"label\": 0, \"prob\": p_no}\n",
    "\n",
    "    elif method == 'logit':\n",
    "        resp = client.chat.completions.create(\n",
    "            model=\"Qwen3-Next-80B-A3B-Thinking\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=200,\n",
    "            temperature=0.7,\n",
    "        )\n",
    "        text = resp.choices[0].message.content.strip()\n",
    "        logit_yes, logit_no = parse_logits(text)\n",
    "        p_yes = sigmoid(logit_yes)\n",
    "        p_no = sigmoid(logit_no)\n",
    "\n",
    "        if p_yes >= p_no:\n",
    "            return {\"label\": 1, \"prob\": p_yes}\n",
    "        else:\n",
    "            return {\"label\": 0, \"prob\": p_no}\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Method should be one of 'frequency', 'probability', or 'logit'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "256cddd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_backdoor(x1, x2, method='logit'):\n",
    "    prompt = f\"请判断 {x1} 与 {x2} 之间是否存在 back-door path。\" \\\n",
    "             f\"请直接输出是和否的概率对，并确保满足 Kolmogorov 公理。\"\n",
    "    return llm_judge_openai(prompt, x1, x2, method)\n",
    "\n",
    "def check_independence_after_block(x1, x2, method='logit'):\n",
    "    prompt = f\"阻断 back-door path 后，{x1} 与 {x2} 是否独立？\" \\\n",
    "             f\"请直接输出是和否的概率对，并确保满足 Kolmogorov 公理。\"\n",
    "    return llm_judge_openai(prompt, x1, x2, method)\n",
    "\n",
    "def check_latent_confounder_after_block(x1, x2, method='logit'):\n",
    "    prompt = f\"阻断 back-door path 后，{x1} 与 {x2} 是否存在潜在混杂因子？\" \\\n",
    "             f\"请直接输出是和否的概率对，并确保满足 Kolmogorov 公理。\"\n",
    "    return llm_judge_openai(prompt, x1, x2, method)\n",
    "\n",
    "def check_causal_direction_after_block(x1, x2, method='logit'):\n",
    "    prompt = f\"阻断 back-door path 后，请判断 {x1} 是否会导致 {x2}。\" \\\n",
    "             f\"请直接输出是和否的概率对，并确保满足 Kolmogorov 公理。\"\n",
    "    return llm_judge_openai(prompt, x1, x2, method)\n",
    "\n",
    "def check_independence(x1, x2, method='logit'):\n",
    "    prompt = f\"请判断 {x1} 与 {x2} 是否独立。\" \\\n",
    "             f\"请直接输出是和否的概率对，并确保满足 Kolmogorov 公理。\"\n",
    "    return llm_judge_openai(prompt, x1, x2, method)\n",
    "\n",
    "def check_latent_confounder(x1, x2, method='logit'):\n",
    "    prompt = f\"请判断 {x1} 与 {x2} 之间是否存在潜在混杂因子。\" \\\n",
    "             f\"请直接输出是和否的概率对，并确保满足 Kolmogorov 公理。\"\n",
    "    return llm_judge_openai(prompt, x1, x2, method)\n",
    "\n",
    "def check_causal_direction(x1, x2, method='logit'):\n",
    "    prompt = f\"请判断 {x1} 是否会导致 {x2}。\" \\\n",
    "             f\"请请直接输出是和否的概率对，并确保满足 Kolmogorov 公理。\"\n",
    "    return llm_judge_openai(prompt, x1, x2, method)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18f0599d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: LLM 生成因果知识\n",
    "def tree_query(x1, x2, method='probability'):\n",
    "    \"\"\"\n",
    "    基于树状逻辑的因果方向查询器（不做阈值判断）。\n",
    "    每一步子检查函数都返回: {\"label\": 1或0, \"prob\": float}\n",
    "\n",
    "    输出:\n",
    "        {\n",
    "            'relation': 'x->y' | 'y->x' | 'x<->y' | 'independent',\n",
    "            'confidence': float,   # 取决定该结论的那一步的 prob\n",
    "            'log': [(step_name, {'label': int, 'prob': float}), ...]\n",
    "        }\n",
    "    \"\"\"\n",
    "    log = []\n",
    "\n",
    "    # Step 1: 是否存在 backdoor path?\n",
    "    res_backdoor = check_backdoor(x1, x2, method)\n",
    "    log.append((\"backdoor_path\", res_backdoor))\n",
    "\n",
    "    if res_backdoor[\"label\"] == 1:\n",
    "        # Step 2: 阻断路径后是否独立？\n",
    "        res_ind = check_independence_after_block(x1, x2, method)\n",
    "        log.append((\"independent_after_block\", res_ind))\n",
    "        if res_ind[\"label\"] == 1:\n",
    "            return {\"relation\": \"independent\", \"confidence\": res_ind[\"prob\"], \"log\": log}\n",
    "\n",
    "        # Step 3: 是否存在潜在混杂因子？\n",
    "        res_latent = check_latent_confounder_after_block(x1, x2, method)\n",
    "        log.append((\"latent_confounder_after_block\", res_latent))\n",
    "        if res_latent[\"label\"] == 1:\n",
    "            return {\"relation\": \"x<->y\", \"confidence\": res_latent[\"prob\"], \"log\": log}\n",
    "\n",
    "        # Step 4: 判断方向 (x→y?)\n",
    "        res_dir = check_causal_direction_after_block(x1, x2, method)\n",
    "        log.append((\"x->y_after_block\", res_dir))\n",
    "        if res_dir[\"label\"] == 1:\n",
    "            return {\"relation\": \"x->y\", \"confidence\": res_dir[\"prob\"], \"log\": log}\n",
    "        else:\n",
    "            return {\"relation\": \"y->x\", \"confidence\": res_dir[\"prob\"], \"log\": log}\n",
    "\n",
    "    else:\n",
    "        # 不存在 backdoor path\n",
    "        res_ind = check_independence(x1, x2, method)\n",
    "        log.append((\"independent_no_backdoor\", res_ind))\n",
    "        if res_ind[\"label\"] == 1:\n",
    "            return {\"relation\": \"independent\", \"confidence\": res_ind[\"prob\"], \"log\": log}\n",
    "\n",
    "        res_latent = check_latent_confounder(x1, x2, method)\n",
    "        log.append((\"latent_confounder_no_backdoor\", res_latent))\n",
    "        if res_latent[\"label\"] == 1:\n",
    "            return {\"relation\": \"x<->y\", \"confidence\": res_latent[\"prob\"], \"log\": log}\n",
    "\n",
    "        res_dir = check_causal_direction(x1, x2, method)\n",
    "        log.append((\"x->y_no_backdoor\", res_dir))\n",
    "        if res_dir[\"label\"] == 1:\n",
    "            return {\"relation\": \"x->y\", \"confidence\": res_dir[\"prob\"], \"log\": log}\n",
    "        else:\n",
    "            return {\"relation\": \"y->x\", \"confidence\": res_dir[\"prob\"], \"log\": log}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16949b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始因果推断分析...\n",
      "=== Step 1: 检查后门路径 ===\n",
      "门诊agent原始响应: graph_theory,domain_knowledge,statistical\n",
      "门诊agent推荐: ['graph_theory', 'domain_knowledge', 'statistical']\n",
      "为问题 'backdoor_path' 选择的专家: ['graph_theory', 'domain_knowledge', 'statistical']\n",
      "专家 graph_theory 判断完成: label=1, prob=1.0\n",
      "专家 domain_knowledge 判断完成: label=1, prob=1.0\n",
      "专家 statistical 判断完成: label=1, prob=1.0\n",
      "专家整合结果: label=1, prob=1.0\n",
      "存在后门路径，进入阻断后分析路径\n",
      "=== Step 2: 阻断后检查独立性 ===\n",
      "门诊agent原始响应: domain_knowledge, graph_theory, statistical\n",
      "门诊agent推荐: ['domain_knowledge', 'graph_theory', 'statistical']\n",
      "为问题 'independence' 选择的专家: ['domain_knowledge', 'graph_theory', 'statistical']\n",
      "专家 domain_knowledge 判断完成: label=1, prob=1.0\n",
      "专家 graph_theory 判断完成: label=1, prob=1.0\n",
      "专家 statistical 判断完成: label=1, prob=1.0\n",
      "专家整合结果: label=1, prob=1.0\n",
      "\n",
      "=== 最终结果 ===\n",
      "关系: independent\n",
      "置信度: 1.0\n",
      "\n",
      "=== 详细执行日志 ===\n",
      "backdoor_path: {'label': 1, 'prob': 1.0, 'expert_results': [{'label': 1, 'prob': 1.0, 'expert': 'graph_theory', 'confidence': 1.0}, {'label': 1, 'prob': 1.0, 'expert': 'domain_knowledge', 'confidence': 1.0}, {'label': 1, 'prob': 1.0, 'expert': 'statistical', 'confidence': 1.0}]}\n",
      "  专家详情: [('graph_theory', 1, 1.0), ('domain_knowledge', 1, 1.0), ('statistical', 1, 1.0)]\n",
      "independent_after_block: {'label': 1, 'prob': 1.0, 'expert_results': [{'label': 1, 'prob': 1.0, 'expert': 'domain_knowledge', 'confidence': 1.0}, {'label': 1, 'prob': 1.0, 'expert': 'graph_theory', 'confidence': 1.0}, {'label': 1, 'prob': 1.0, 'expert': 'statistical', 'confidence': 1.0}]}\n",
      "  专家详情: [('domain_knowledge', 1, 1.0), ('graph_theory', 1, 1.0), ('statistical', 1, 1.0)]\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import math\n",
    "import re\n",
    "from typing import List, Dict, Any, Tuple\n",
    "\n",
    "client = openai.OpenAI(\n",
    "    api_key=\"sk-JBfp0POD11gasNLNn1uTiQ\",  \n",
    "    base_url=\"https://llmapi.paratera.com/v1/\"\n",
    ")\n",
    "\n",
    "# === 工具函数 ===\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "def parse_probabilities(llm_output: str):\n",
    "    \"\"\"\n",
    "    从 LLM 文本输出中提取概率。\n",
    "    比如：\n",
    "    P(yes) = 0.0  \n",
    "    P(no) = 1.0\n",
    "    \"\"\"\n",
    "    matches = re.findall(r\"([0-9]*\\.?[0-9]+)\", llm_output)\n",
    "    if len(matches) >= 2:\n",
    "        p1, p2 = float(matches[0]), float(matches[1])\n",
    "        total = p1 + p2\n",
    "        if total == 0:\n",
    "            return 0.5, 0.5\n",
    "        return p1 / total, p2 / total\n",
    "    return 0.5, 0.5  # fallback\n",
    "\n",
    "def parse_logits(llm_output: str):\n",
    "    matches = re.findall(r\"([-]?[0-9]*\\.?[0-9]+)\", llm_output)\n",
    "    if len(matches) >= 2:\n",
    "        l1, l2 = float(matches[0]), float(matches[1])\n",
    "        if not math.isclose(l1 + l2, 0):\n",
    "            avg = (l1 - l2) / 2\n",
    "            l1, l2 = avg, -avg\n",
    "        return l1, l2\n",
    "    return 0.0, 0.0\n",
    "\n",
    "def llm_judge_openai(prompt, x1, x2, method='frequency', n_sample=10):\n",
    "    \"\"\"\n",
    "    使用 client.chat.completions.create\n",
    "    method: 'frequency' | 'probability' | 'logit'\n",
    "    返回: {\"label\": 1或0, \"prob\": 最大概率}\n",
    "    \"\"\"\n",
    "\n",
    "    if method == 'frequency':\n",
    "        votes = []\n",
    "        for _ in range(n_sample):\n",
    "            resp = client.chat.completions.create(\n",
    "                model=\"Qwen3-Next-80B-A3B-Thinking\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                max_tokens=50,\n",
    "                temperature=0.7,\n",
    "            )\n",
    "            text = resp.choices[0].message.content.strip()\n",
    "            votes.append(1 if text.lower().startswith(\"yes\") else 0)\n",
    "\n",
    "        p_yes = sum(votes) / len(votes)\n",
    "        p_no = 1 - p_yes\n",
    "        # 取最大标签与其概率（平局默认选 yes=>1）\n",
    "        if p_yes >= p_no:\n",
    "            return {\"label\": 1, \"prob\": p_yes}\n",
    "        else:\n",
    "            return {\"label\": 0, \"prob\": p_no}\n",
    "\n",
    "    elif method == 'probability':\n",
    "        resp = client.chat.completions.create(\n",
    "            model=\"Qwen3-Next-80B-A3B-Thinking\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=200,\n",
    "            temperature=0.7,\n",
    "        )\n",
    "        text = resp.choices[0].message.content.strip()\n",
    "        #print(\"LLM 原始输出：\\n\", text)  # 调试用\n",
    "\n",
    "        p_yes, p_no = parse_probabilities(text)\n",
    "        if p_yes >= p_no:\n",
    "            return {\"label\": 1, \"prob\": p_yes}\n",
    "        else:\n",
    "            return {\"label\": 0, \"prob\": p_no}\n",
    "\n",
    "    elif method == 'logit':\n",
    "        resp = client.chat.completions.create(\n",
    "            model=\"Qwen3-Next-80B-A3B-Thinking\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=200,\n",
    "            temperature=0.7,\n",
    "        )\n",
    "        text = resp.choices[0].message.content.strip()\n",
    "        logit_yes, logit_no = parse_logits(text)\n",
    "        p_yes = sigmoid(logit_yes)\n",
    "        p_no = sigmoid(logit_no)\n",
    "\n",
    "        if p_yes >= p_no:\n",
    "            return {\"label\": 1, \"prob\": p_yes}\n",
    "        else:\n",
    "            return {\"label\": 0, \"prob\": p_no}\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Method should be one of 'frequency', 'probability', or 'logit'\")\n",
    "\n",
    "# === MoE 专家定义 ===\n",
    "CAUSAL_EXPERTS = {\n",
    "    \"graph_theory\": {\n",
    "        \"name\": \"因果图论专家\",\n",
    "        \"description\": \"专门分析因果图结构，精通d-分离、路径阻断、后门准则等图论概念。推理方式：系统检查所有可能的路径，分析路径上的变量类型和连接方式，使用严谨的图论推理链条。\",\n",
    "        \"specialty\": \"路径分析、环路检测、d-分离判断\",\n",
    "        \"reasoning_style\": \"结构化图遍历\",\n",
    "        \"output_format\": \"基于图结构的二值判断\"\n",
    "    },\n",
    "    \"statistical\": {\n",
    "        \"name\": \"计量统计专家\", \n",
    "        \"description\": \"专注于统计检验和概率独立性分析，擅长相关性分析、条件独立性检验、混淆变量检测。推理方式：考虑样本分布、统计显著性、置信区间等统计概念。\",\n",
    "        \"specialty\": \"独立性检验、相关性分析、混淆检测\",\n",
    "        \"reasoning_style\": \"概率统计推理\",\n",
    "        \"output_format\": \"基于统计证据的概率判断\"\n",
    "    },\n",
    "    \"domain_knowledge\": {\n",
    "        \"name\": \"领域先验专家\",\n",
    "        \"description\": \"基于现实世界知识和科学常识进行因果推理，考虑时间顺序、物理可能性、生物学机制等约束。推理方式：结合文献证据、科学理论和常识性约束。\",\n",
    "        \"specialty\": \"机制分析、时序推理、现实约束\",\n",
    "        \"reasoning_style\": \"基于证据的归纳推理\", \n",
    "        \"output_format\": \"基于领域知识的合理性判断\"\n",
    "    },\n",
    "    \"counterfactual\": {\n",
    "        \"name\": \"反事实干预专家\",\n",
    "        \"description\": \"从干预和潜在结果角度分析因果关系，考虑do-calculus、随机化实验理想情况。推理方式：构建反事实场景，分析干预后的可能变化。\",\n",
    "        \"specialty\": \"干预分析、潜在结果、do算子\",\n",
    "        \"reasoning_style\": \"反事实思维实验\",\n",
    "        \"output_format\": \"基于干预推理的因果判断\"\n",
    "    },\n",
    "    \"temporal_dynamics\": {\n",
    "        \"name\": \"时间动态专家\",\n",
    "        \"description\": \"专门分析时间顺序和动态过程，强调原因必须发生在结果之前，考虑延迟效应和动态反馈。推理方式：严格检查时间顺序，分析因果链的时间特性。\",\n",
    "        \"specialty\": \"时序分析、动态过程、延迟效应\",\n",
    "        \"reasoning_style\": \"时间序列推理\", \n",
    "        \"output_format\": \"基于时间顺序的因果判断\"\n",
    "    },\n",
    "    \"mechanism_modeling\": {\n",
    "        \"name\": \"机制建模专家\", \n",
    "        \"description\": \"专注于因果机制的可解释性建模，分析中间变量、中介效应和机制路径。推理方式：构建机制框图，分析变量间的功能关系。\",\n",
    "        \"specialty\": \"中介分析、机制路径、功能关系\",\n",
    "        \"reasoning_style\": \"机制分解建模\",\n",
    "        \"output_format\": \"基于机制完整性的判断\"\n",
    "    },\n",
    "    \"robustness_analysis\": {\n",
    "        \"name\": \"稳健性检验专家\",\n",
    "        \"description\": \"专门评估因果关系的稳健性和敏感性，考虑不同假设下的结果稳定性。推理方式：进行敏感性分析，检验边界条件和假设变化的影响。\",\n",
    "        \"specialty\": \"敏感性分析、稳健检验、边界情况\",\n",
    "        \"reasoning_style\": \"多情景验证\",\n",
    "        \"output_format\": \"基于稳健性评估的判断\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# === Router 函数（增强版）===\n",
    "def expert_router(question_type: str, x1: str, x2: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    根据问题类型和变量特征选择最相关的专家\n",
    "    返回专家名称列表，按相关性排序\n",
    "    \"\"\"\n",
    "    # 基础路由规则\n",
    "    routing_rules = {\n",
    "        \"backdoor_path\": [\n",
    "            \"graph_theory\", \"statistical\", \"counterfactual\", \"temporal_dynamics\", \n",
    "            \"mechanism_modeling\", \"robustness_analysis\", \"domain_knowledge\"\n",
    "        ],\n",
    "        \"independence\": [\n",
    "            \"statistical\", \"graph_theory\", \"counterfactual\", \"robustness_analysis\",\n",
    "            \"temporal_dynamics\", \"mechanism_modeling\", \"domain_knowledge\"\n",
    "        ],\n",
    "        \"latent_confounder\": [\n",
    "            \"domain_knowledge\", \"statistical\", \"mechanism_modeling\", \"counterfactual\",\n",
    "            \"robustness_analysis\", \"graph_theory\", \"temporal_dynamics\"\n",
    "        ],\n",
    "        \"causal_direction\": [\n",
    "            \"temporal_dynamics\", \"domain_knowledge\", \"counterfactual\", \"mechanism_modeling\",\n",
    "            \"statistical\", \"graph_theory\", \"robustness_analysis\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # 获取基础专家列表\n",
    "    base_experts = routing_rules.get(question_type, list(CAUSAL_EXPERTS.keys()))\n",
    "    \n",
    "    # 使用门诊LLM agent来智能选择专家\n",
    "    try:\n",
    "        clinic_recommendation = clinic_agent_recommend(question_type, x1, x2, base_experts)\n",
    "        return clinic_recommendation\n",
    "    except Exception as e:\n",
    "        print(f\"门诊agent路由失败: {e}，使用基础路由\")\n",
    "        # 失败时返回基础专家列表的前3个\n",
    "        return base_experts[:3]\n",
    "\n",
    "def clinic_agent_recommend(question_type: str, x1: str, x2: str, base_experts: List[str]) -> List[str]:\n",
    "    \"\"\"\n",
    "    门诊LLM agent：根据具体变量和问题类型推荐最相关的专家\n",
    "    \"\"\"\n",
    "    # 构建专家选择提示\n",
    "    experts_description = \"\\n\".join([\n",
    "        f\"- {expert}: {CAUSAL_EXPERTS[expert]['description']}\" \n",
    "        for expert in base_experts\n",
    "    ])\n",
    "    \n",
    "    clinic_prompt = f\"\"\"\n",
    "作为因果推断门诊专家，你需要为以下因果分析任务选择最合适的专家组合：\n",
    "\n",
    "**分析任务**: {question_type}\n",
    "**变量对**: {x1} 和 {x2}\n",
    "\n",
    "**可用专家列表**:\n",
    "{experts_description}\n",
    "\n",
    "**选择要求**:\n",
    "1. 根据变量内容和问题类型，选择最相关的3个专家\n",
    "2. 按相关性从高到低排序\n",
    "3. 确保专家视角的多样性（不要选择推理方式相似的专家）\n",
    "4. 考虑变量的领域特性（医学、经济、社会等）\n",
    "\n",
    "请按照以下格式输出：\n",
    "最终推荐专家: 专家1, 专家2, 专家3\n",
    "\n",
    "**注意**: 只输出专家名称，用逗号分隔，不要添加其他文字。\n",
    "\"\"\"\n",
    "    \n",
    "    # 调用LLM获取推荐\n",
    "    resp = client.chat.completions.create(\n",
    "        model=\"Qwen3-Next-80B-A3B-Thinking\",\n",
    "        messages=[{\"role\": \"user\", \"content\": clinic_prompt}],\n",
    "        max_tokens=200,  # 减少token使用\n",
    "        temperature=0.1,  # 降低随机性\n",
    "    )\n",
    "    \n",
    "    response_text = resp.choices[0].message.content.strip()\n",
    "    print(f\"门诊agent原始响应: {response_text}\")\n",
    "    \n",
    "    # 解析返回的专家列表\n",
    "    recommended_experts = parse_clinic_recommendation(response_text, base_experts)\n",
    "    \n",
    "    print(f\"门诊agent推荐: {recommended_experts}\")\n",
    "    \n",
    "    return recommended_experts\n",
    "\n",
    "def parse_clinic_recommendation(response_text: str, base_experts: List[str]) -> List[str]:\n",
    "    \"\"\"\n",
    "    解析门诊agent的推荐结果 - 改进版本\n",
    "    \"\"\"\n",
    "    # 方法1: 查找\"最终推荐专家\"后的内容\n",
    "    if \"最终推荐专家\" in response_text:\n",
    "        parts = response_text.split(\"最终推荐专家\")\n",
    "        if len(parts) > 1:\n",
    "            expert_line = parts[1].strip().lstrip(\":\").strip()\n",
    "            return extract_experts_from_line(expert_line, base_experts)\n",
    "    \n",
    "    # 方法2: 查找最后一行\n",
    "    lines = [line.strip() for line in response_text.split('\\n') if line.strip()]\n",
    "    if lines:\n",
    "        last_line = lines[-1]\n",
    "        experts = extract_experts_from_line(last_line, base_experts)\n",
    "        if len(experts) >= 2:\n",
    "            return experts\n",
    "    \n",
    "    # 方法3: 在整个文本中搜索专家名称\n",
    "    found_experts = []\n",
    "    for expert in base_experts:\n",
    "        if expert in response_text:\n",
    "            found_experts.append(expert)\n",
    "    \n",
    "    if len(found_experts) >= 2:\n",
    "        return found_experts[:3]  # 取前3个找到的专家\n",
    "    \n",
    "    # 如果所有方法都失败，返回基础专家前3个\n",
    "    print(f\"门诊agent解析不充分，使用基础专家: {base_experts[:3]}\")\n",
    "    return base_experts[:3]\n",
    "\n",
    "# === 增强解析函数 ===\n",
    "def extract_experts_from_line(line: str, base_experts: List[str]) -> List[str]:\n",
    "    \"\"\"从一行文本中提取专家名称 - 增强版本\"\"\"\n",
    "    experts = []\n",
    "    \n",
    "    # 清理行内容，移除可能的中文标点和空格\n",
    "    clean_line = line.replace('：', ':').replace('，', ',').replace(' ', '')\n",
    "    \n",
    "    # 多种分割方式尝试\n",
    "    separators = [',', '、', ';', '，']\n",
    "    \n",
    "    for sep in separators:\n",
    "        if sep in clean_line:\n",
    "            parts = [part.strip() for part in clean_line.split(sep)]\n",
    "            break\n",
    "    else:\n",
    "        # 如果没有分隔符，尝试按长度分割\n",
    "        parts = [clean_line]\n",
    "    \n",
    "    for part in parts:\n",
    "        # 移除可能的前缀和后缀\n",
    "        clean_part = part.lower().replace('专家', '').replace('expert', '').strip()\n",
    "        \n",
    "        # 直接匹配专家名称\n",
    "        for expert in base_experts:\n",
    "            # 多种匹配方式\n",
    "            if (expert in clean_part or \n",
    "                expert.replace('_', ' ') in clean_part or\n",
    "                CAUSAL_EXPERTS[expert]['name'] in part):\n",
    "                if expert not in experts:  # 避免重复\n",
    "                    experts.append(expert)\n",
    "                    break\n",
    "        \n",
    "        # 如果已经找到3个专家，停止搜索\n",
    "        if len(experts) >= 3:\n",
    "            break\n",
    "    \n",
    "    return experts\n",
    "\n",
    "def create_expert_prompt(base_prompt: str, expert_type: str, x1: str, x2: str) -> str:\n",
    "    \"\"\"\n",
    "    为不同专家创建专业化的prompt\n",
    "    \"\"\"\n",
    "    expert_info = CAUSAL_EXPERTS[expert_type]\n",
    "    \n",
    "    expert_specific_prompts = {\n",
    "        \"graph_theory\": f\"\"\"作为{expert_info['name']}，请严格遵循以下专业分析框架：\n",
    "\n",
    "{expert_info['description']}\n",
    "\n",
    "专业特长：{expert_info['specialty']}\n",
    "推理风格：{expert_info['reasoning_style']}\n",
    "输出要求：基于图结构的二值判断\n",
    "\n",
    "分析步骤：\n",
    "1. 构建因果图模型，识别所有可能的路径\n",
    "2. 应用d-分离准则分析路径阻塞情况  \n",
    "3. 检查后门路径、前门路径和混杂路径\n",
    "4. 基于图结构做出明确的二值判断\n",
    "\n",
    "请严格按照图论原理进行分析，直接输出是或否（Yes/No）。\\n\\n{base_prompt}\"\"\",\n",
    "\n",
    "        \"statistical\": f\"\"\"作为{expert_info['name']}，请严格遵循以下专业分析框架：\n",
    "\n",
    "{expert_info['description']}\n",
    "\n",
    "专业特长：{expert_info['specialty']}\n",
    "推理风格：{expert_info['reasoning_style']}\n",
    "输出要求：基于统计证据的二值判断\n",
    "\n",
    "分析步骤：\n",
    "1. 评估变量间的统计相关性\n",
    "2. 考虑条件独立性和混淆因素\n",
    "3. 分析统计显著性和置信度\n",
    "4. 基于概率证据做出明确的二值判断\n",
    "\n",
    "请基于统计原理进行严谨分析，直接输出是或否（Yes/No）。\\n\\n{base_prompt}\"\"\",\n",
    "\n",
    "        \"domain_knowledge\": f\"\"\"作为{expert_info['name']}，请严格遵循以下专业分析框架：\n",
    "\n",
    "{expert_info['description']}\n",
    "\n",
    "专业特长：{expert_info['specialty']}\n",
    "推理风格：{expert_info['reasoning_style']}\n",
    "输出要求：基于领域知识的二值判断\n",
    "\n",
    "分析步骤：\n",
    "1. 调用相关领域的科学知识和常识\n",
    "2. 考虑物理/生物/社会机制的合理性\n",
    "3. 评估时间顺序和现实约束条件\n",
    "4. 基于先验知识做出明确的二值判断\n",
    "\n",
    "请结合现实世界知识进行推理，直接输出是或否（Yes/No）。\\n\\n{base_prompt}\"\"\",\n",
    "\n",
    "        \"counterfactual\": f\"\"\"作为{expert_info['name']}，请严格遵循以下专业分析框架：\n",
    "\n",
    "{expert_info['description']}\n",
    "\n",
    "专业特长：{expert_info['specialty']}\n",
    "推理风格：{expert_info['reasoning_style']}\n",
    "输出要求：基于干预推理的二值判断\n",
    "\n",
    "分析步骤：\n",
    "1. 构建干预场景（do-操作）\n",
    "2. 比较实际结果与反事实结果\n",
    "3. 分析潜在结果分布\n",
    "4. 基于干预效应做出明确的二值判断\n",
    "\n",
    "请使用反事实推理进行分析，直接输出是或否（Yes/No）。\\n\\n{base_prompt}\"\"\",\n",
    "\n",
    "        \"temporal_dynamics\": f\"\"\"作为{expert_info['name']}，请严格遵循以下专业分析框架：\n",
    "\n",
    "{expert_info['description']}\n",
    "\n",
    "专业特长：{expert_info['specialty']}\n",
    "推理风格：{expert_info['reasoning_style']}\n",
    "输出要求：基于时间顺序的二值判断\n",
    "\n",
    "分析步骤：\n",
    "1. 严格检查原因和结果的时间顺序\n",
    "2. 分析延迟效应和动态过程\n",
    "3. 考虑时间序列的因果结构\n",
    "4. 基于时间约束做出明确的二值判断\n",
    "\n",
    "请重点分析时间维度，直接输出是或否（Yes/No）。\\n\\n{base_prompt}\"\"\",\n",
    "\n",
    "        \"mechanism_modeling\": f\"\"\"作为{expert_info['name']}，请严格遵循以下专业分析框架：\n",
    "\n",
    "{expert_info['description']}\n",
    "\n",
    "专业特长：{expert_info['specialty']}\n",
    "推理风格：{expert_info['reasoning_style']}\n",
    "输出要求：基于机制完整性的二值判断\n",
    "\n",
    "分析步骤：\n",
    "1. 识别可能的中间机制和中介变量\n",
    "2. 分析因果链的功能完整性\n",
    "3. 评估机制路径的合理性\n",
    "4. 基于机制可解释性做出明确的二值判断\n",
    "\n",
    "请专注于机制分析，直接输出是或否（Yes/No）。\\n\\n{base_prompt}\"\"\",\n",
    "\n",
    "        \"robustness_analysis\": f\"\"\"作为{expert_info['name']}，请严格遵循以下专业分析框架：\n",
    "\n",
    "{expert_info['description']}\n",
    "\n",
    "专业特长：{expert_info['specialty']}\n",
    "推理风格：{expert_info['reasoning_style']}\n",
    "输出要求：基于稳健性评估的二值判断\n",
    "\n",
    "分析步骤：\n",
    "1. 测试不同假设条件下的结果稳定性\n",
    "2. 进行敏感性分析和边界检验\n",
    "3. 评估结论的稳健程度\n",
    "4. 基于稳健性评估做出明确的二值判断\n",
    "\n",
    "请重点分析结论的可靠性，直接输出是或否（Yes/No）。\\n\\n{base_prompt}\"\"\"\n",
    "    }\n",
    "    \n",
    "    return expert_specific_prompts.get(expert_type, base_prompt)\n",
    "\n",
    "# === MoE 集成函数 ===\n",
    "def aggregate_expert_judgments(expert_results: List[Dict]) -> Dict:\n",
    "    \"\"\"\n",
    "    整合多个专家的判断结果\n",
    "    \"\"\"\n",
    "    if not expert_results:\n",
    "        return {\"label\": 0, \"prob\": 0.5}\n",
    "    \n",
    "    # 简单加权平均\n",
    "    total_prob_yes = 0\n",
    "    total_weight = 0\n",
    "    \n",
    "    for result in expert_results:\n",
    "        weight = result.get(\"confidence\", 1.0)\n",
    "        prob_yes = result[\"prob\"] if result[\"label\"] == 1 else 1 - result[\"prob\"]\n",
    "        total_prob_yes += prob_yes * weight\n",
    "        total_weight += weight\n",
    "    \n",
    "    aggregated_prob_yes = total_prob_yes / total_weight if total_weight > 0 else 0.5\n",
    "    \n",
    "    if aggregated_prob_yes >= 0.5:\n",
    "        return {\"label\": 1, \"prob\": aggregated_prob_yes}\n",
    "    else:\n",
    "        return {\"label\": 0, \"prob\": 1 - aggregated_prob_yes}\n",
    "\n",
    "# === 修改后的 run_step_with_moe 函数 ===\n",
    "def run_step_with_moe(base_prompt: str, x1: str, x2: str, question_type: str, method: str = 'frequency') -> Dict:\n",
    "    \"\"\"\n",
    "    使用MoE架构运行单个判断步骤\n",
    "    \"\"\"\n",
    "    # 注意：这里我们不需要修改，因为base_prompt已经包含了all_variables\n",
    "    # 1. 路由选择专家\n",
    "    selected_experts = expert_router(question_type, x1, x2)\n",
    "    print(f\"为问题 '{question_type}' 选择的专家: {selected_experts}\")\n",
    "    \n",
    "    # 2. 执行专家判断\n",
    "    expert_results = []\n",
    "    for expert in selected_experts:  # 使用所有推荐的专家\n",
    "        expert_prompt = create_expert_prompt(base_prompt, expert, x1, x2)\n",
    "        try:\n",
    "            result = llm_judge_openai(expert_prompt, x1, x2, method)\n",
    "            result[\"expert\"] = expert\n",
    "            result[\"confidence\"] = 1.0\n",
    "            expert_results.append(result)\n",
    "            print(f\"专家 {expert} 判断完成: label={result['label']}, prob={result['prob']}\")\n",
    "        except Exception as e:\n",
    "            print(f\"专家 {expert} 执行失败: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # 3. 如果没有专家成功，使用默认方法\n",
    "    if not expert_results:\n",
    "        print(\"所有专家执行失败，使用默认方法\")\n",
    "        return llm_judge_openai(base_prompt, x1, x2, method)\n",
    "    \n",
    "    # 4. 整合专家意见\n",
    "    final_result = aggregate_expert_judgments(expert_results)\n",
    "    final_result[\"expert_results\"] = expert_results\n",
    "    \n",
    "    print(f\"专家整合结果: label={final_result['label']}, prob={final_result['prob']}\")\n",
    "    return final_result\n",
    "\n",
    "# === 修改后的具体判断函数 ===\n",
    "def check_backdoor(x1, x2, all_variables, method='frequency'):\n",
    "    base_prompt = f\"\"\"在因果推断中，考虑以下所有变量：{all_variables}\n",
    "\n",
    "请判断在这些变量中，变量 {x1} 和 {x2} 之间是否存在 back-door path（后门路径）。\n",
    "\n",
    "后门路径是指从 {x1} 到 {x2} 的路径，其中包含指向 {x1} 的箭头，且这条路径没有被阻断。\n",
    "\n",
    "让我们一步步思考，然后直接输出是或否（Yes/No）。\"\"\"\n",
    "    return run_step_with_moe(base_prompt, x1, x2, \"backdoor_path\", method)\n",
    "\n",
    "def check_independence_after_block(x1, x2, all_variables, method='frequency'):\n",
    "    base_prompt = f\"\"\"在因果推断中，考虑以下所有变量：{all_variables}\n",
    "\n",
    "如果阻断了 {x1} 和 {x2} 之间的所有 back-door path，那么 {x1} 与 {x2} 是否条件独立？\n",
    "\n",
    "让我们一步步思考，然后直接输出是或否（Yes/No）。\"\"\"\n",
    "    return run_step_with_moe(base_prompt, x1, x2, \"independence\", method)\n",
    "\n",
    "def check_latent_confounder_after_block(x1, x2, all_variables, method='frequency'):\n",
    "    base_prompt = f\"\"\"在因果推断中，考虑以下所有变量：{all_variables}\n",
    "\n",
    "阻断了 {x1} 和 {x2} 之间的所有 back-door path 后，是否仍然存在未观察到的潜在混杂因子同时影响 {x1} 和 {x2}？\n",
    "\n",
    "让我们一步步思考，然后直接输出是或否（Yes/No）。\"\"\"\n",
    "    return run_step_with_moe(base_prompt, x1, x2, \"latent_confounder\", method)\n",
    "\n",
    "def check_causal_direction_after_block(x1, x2, all_variables, method='frequency'):\n",
    "    base_prompt = f\"\"\"在因果推断中，考虑以下所有变量：{all_variables}\n",
    "\n",
    "阻断了 {x1} 和 {x2} 之间的所有 back-door path 后，请判断 {x1} 是否因果导致 {x2}？\n",
    "\n",
    "让我们一步步思考，然后直接输出是或否（Yes/No）。\"\"\"\n",
    "    return run_step_with_moe(base_prompt, x1, x2, \"causal_direction\", method)\n",
    "\n",
    "def check_independence(x1, x2, all_variables, method='frequency'):\n",
    "    base_prompt = f\"\"\"在因果推断中，考虑以下所有变量：{all_variables}\n",
    "\n",
    "请判断变量 {x1} 和 {x2} 是否独立？\n",
    "\n",
    "让我们一步步思考，然后直接输出是或否（Yes/No）。\"\"\"\n",
    "    return run_step_with_moe(base_prompt, x1, x2, \"independence\", method)\n",
    "\n",
    "def check_latent_confounder(x1, x2, all_variables, method='frequency'):\n",
    "    base_prompt = f\"\"\"在因果推断中，考虑以下所有变量：{all_variables}\n",
    "\n",
    "请判断变量 {x1} 和 {x2} 之间是否存在未观察到的潜在混杂因子？\n",
    "\n",
    "让我们一步步思考，然后直接输出是或否（Yes/No）。\"\"\"\n",
    "    return run_step_with_moe(base_prompt, x1, x2, \"latent_confounder\", method)\n",
    "\n",
    "def check_causal_direction(x1, x2, all_variables, method='frequency'):\n",
    "    base_prompt = f\"\"\"在因果推断中，考虑以下所有变量：{all_variables}\n",
    "\n",
    "请判断 {x1} 是否因果导致 {x2}？\n",
    "\n",
    "让我们一步步思考，然后直接输出是或否（Yes/No）。\"\"\"\n",
    "    return run_step_with_moe(base_prompt, x1, x2, \"causal_direction\", method)\n",
    "\n",
    "# === 修改后的 tree_query 函数 ===\n",
    "def tree_query(x1, x2, all_variables, method='frequency'):\n",
    "    \"\"\"\n",
    "    基于树状逻辑的因果方向查询器（使用MoE架构）\n",
    "    \"\"\"\n",
    "    log = []\n",
    "\n",
    "    # Step 1: 是否存在 backdoor path?\n",
    "    print(\"=== Step 1: 检查后门路径 ===\")\n",
    "    res_backdoor = check_backdoor(x1, x2, all_variables, method)\n",
    "    log.append((\"backdoor_path\", res_backdoor))\n",
    "\n",
    "    if res_backdoor[\"label\"] == 1:\n",
    "        print(\"存在后门路径，进入阻断后分析路径\")\n",
    "        # Step 2: 阻断路径后是否独立？\n",
    "        print(\"=== Step 2: 阻断后检查独立性 ===\")\n",
    "        res_ind = check_independence_after_block(x1, x2, all_variables, method)\n",
    "        log.append((\"independent_after_block\", res_ind))\n",
    "        if res_ind[\"label\"] == 1:\n",
    "            return {\"relation\": \"independent\", \"confidence\": res_ind[\"prob\"], \"log\": log}\n",
    "\n",
    "        # Step 3: 是否存在潜在混杂因子？\n",
    "        print(\"=== Step 3: 检查潜在混杂因子 ===\")\n",
    "        res_latent = check_latent_confounder_after_block(x1, x2, all_variables, method)\n",
    "        log.append((\"latent_confounder_after_block\", res_latent))\n",
    "        if res_latent[\"label\"] == 1:\n",
    "            return {\"relation\": \"x<->y\", \"confidence\": res_latent[\"prob\"], \"log\": log}\n",
    "\n",
    "        # Step 4: 判断方向 (x→y?)\n",
    "        print(\"=== Step 4: 判断因果方向 ===\")\n",
    "        res_dir = check_causal_direction_after_block(x1, x2, all_variables, method)\n",
    "        log.append((\"x->y_after_block\", res_dir))\n",
    "        if res_dir[\"label\"] == 1:\n",
    "            return {\"relation\": \"x->y\", \"confidence\": res_dir[\"prob\"], \"log\": log}\n",
    "        else:\n",
    "            return {\"relation\": \"y->x\", \"confidence\": res_dir[\"prob\"], \"log\": log}\n",
    "\n",
    "    else:\n",
    "        print(\"不存在后门路径，进入直接分析路径\")\n",
    "        # 不存在 backdoor path\n",
    "        res_ind = check_independence(x1, x2, all_variables, method)\n",
    "        log.append((\"independent_no_backdoor\", res_ind))\n",
    "        if res_ind[\"label\"] == 1:\n",
    "            return {\"relation\": \"independent\", \"confidence\": res_ind[\"prob\"], \"log\": log}\n",
    "\n",
    "        res_latent = check_latent_confounder(x1, x2, all_variables, method)\n",
    "        log.append((\"latent_confounder_no_backdoor\", res_latent))\n",
    "        if res_latent[\"label\"] == 1:\n",
    "            return {\"relation\": \"x<->y\", \"confidence\": res_latent[\"prob\"], \"log\": log}\n",
    "\n",
    "        res_dir = check_causal_direction(x1, x2, all_variables, method)\n",
    "        log.append((\"x->y_no_backdoor\", res_dir))\n",
    "        if res_dir[\"label\"] == 1:\n",
    "            return {\"relation\": \"x->y\", \"confidence\": res_dir[\"prob\"], \"log\": log}\n",
    "        else:\n",
    "            return {\"relation\": \"y->x\", \"confidence\": res_dir[\"prob\"], \"log\": log}\n",
    "# === 使用示例 ===\n",
    "if __name__ == \"__main__\":\n",
    "    # 定义完整的变量集合\n",
    "    all_variables = [\"冰淇淋销量\", \"溺水人数\", \"温度\"]\n",
    "    \n",
    "    # 测试MoE框架\n",
    "    print(\"开始因果推断分析...\")\n",
    "    result = tree_query(\"冰淇淋销量\", \"溺水人数\", all_variables, method='frequency')\n",
    "    print(\"\\n=== 最终结果 ===\")\n",
    "    print(\"关系:\", result[\"relation\"])\n",
    "    print(\"置信度:\", result[\"confidence\"])\n",
    "    print(\"\\n=== 详细执行日志 ===\")\n",
    "    for step_name, step_result in result[\"log\"]:\n",
    "        print(f\"{step_name}: {step_result}\")\n",
    "        if \"expert_results\" in step_result:\n",
    "            print(\"  专家详情:\", [(r[\"expert\"], r[\"label\"], r[\"prob\"]) for r in step_result[\"expert_results\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0948bc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def compute_all_causal_relations(variables, method='probability'):\n",
    "    \"\"\"\n",
    "    计算图中每两个变量之间的因果关系，使用tree_query函数。\n",
    "    \n",
    "    输出:\n",
    "        {\n",
    "            (x1, x2): {\n",
    "                'relation': 'x->y' | 'y->x' | 'x<->y' | 'independent',\n",
    "                'confidence': float,\n",
    "                'log': [(step_name, {'label': int, 'prob': float}), ...]\n",
    "            },\n",
    "            ...\n",
    "        }\n",
    "    \"\"\"\n",
    "    all_relations = {}\n",
    "\n",
    "    # 生成所有变量的组合 C(n, 2)\n",
    "    for x1, x2 in combinations(variables, 2):\n",
    "        # 进行 tree_query\n",
    "        result = tree_query(x1, x2, method)\n",
    "        \n",
    "        # 存储结果\n",
    "        all_relations[(x1, x2)] = result\n",
    "\n",
    "    return all_relations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03c57d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM 原始输出：\n",
      " 0.85, 0.15\n",
      "LLM 原始输出：\n",
      " 0,1\n",
      "LLM 原始输出：\n",
      " 0.0 1.0\n",
      "LLM 原始输出：\n",
      " 1.0, 0.0\n",
      "LLM 原始输出：\n",
      " (1, 0)\n",
      "LLM 原始输出：\n",
      " 0.0,1.0\n",
      "LLM 原始输出：\n",
      " 0.5, 0.5\n",
      "LLM 原始输出：\n",
      " 1.0, 0.0\n",
      "LLM 原始输出：\n",
      " 1,0\n",
      "Relation between 气温 and 冰淇淋销量: x->y (Confidence: 1.0)\n",
      "Relation between 气温 and 溺水人数: x<->y (Confidence: 0.5)\n",
      "Relation between 冰淇淋销量 and 溺水人数: independent (Confidence: 1.0)\n"
     ]
    }
   ],
   "source": [
    "variables = ['气温', '冰淇淋销量', '溺水人数']\n",
    "relations = compute_all_causal_relations(variables)\n",
    "\n",
    "for (x1, x2), relation in relations.items():\n",
    "    print(f\"Relation between {x1} and {x2}: {relation['relation']} (Confidence: {relation['confidence']})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a47f78f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM 原始输出：\n",
      " 1.386, -1.386\n",
      "LLM 原始输出：\n",
      " 在因果推断中，阻断 back-door path（后门路径）通常是通过条件在混杂变量（confounder）上来实现，以消除混杂偏差，从而准确估计氟化物（F）对蛀牙（C）的因果效应。在标准因果图（例如，氟化物 → 蛀牙，并有混杂变量 U，如社会经济状态（SES），其中 U → 氟化物 和 U → 蛀牙）中，阻断 back-door path（例如，通过条件在 U 上）后，氟化物与蛀牙之间仍存在直接因果路径（氟化物 → 蛀牙）。因此，氟化物与蛀牙在条件上（给定 U）并不独立，除非因果效应为零（即氟化物对蛀牙无影响）。在现实中，氟化物通常被认为能减少蛀牙风险，因此因果效应存在，独立性不成立。\n",
      "\n",
      "### 回答：\n",
      "- **是否独立？** 否，阻断 back-door path 后\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'relation': 'independent',\n",
       " 'confidence': 0.5,\n",
       " 'log': [('backdoor_path', {'label': 1, 'prob': 0.5}),\n",
       "  ('independent_after_block', {'label': 1, 'prob': 0.5})]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_query('氟化物','蛀牙', method='probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03734d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: 多校准 (multi-Calibration)\n",
    "\n",
    "# 获取语义向量\n",
    "# === Word2Vec提取语义向量 ===\n",
    "def get_word2vec_embeddings(vars_list, model_name=\"word2vec-google-news-300\"):\n",
    "    \"\"\"\n",
    "    使用预训练Word2Vec模型提取变量语义嵌入向量\n",
    "    输入：vars_list - 变量列表\n",
    "    输出：{变量名: 128维向量}\n",
    "    \"\"\"\n",
    "    # 加载预训练Word2Vec模型（首次运行会自动下载，约1.6GB）\n",
    "    print(f\"加载预训练Word2Vec模型：{model_name}...\")\n",
    "    w2v_model = load(model_name)\n",
    "    embeddings = []\n",
    "\n",
    "    for var in vars_list:\n",
    "        # 提取向量：若变量在词汇表中，直接获取；否则生成随机向量\n",
    "        if var in w2v_model.key_to_index:\n",
    "            vec = w2v_model[var]\n",
    "        else:\n",
    "            # 词汇表外变量：生成-1到1的随机向量（符合原需求范围）\n",
    "            vec = np.random.uniform(low=-1.0, high=1.0, size=300)\n",
    "            print(f\"变量「{var}」不在Word2Vec词汇表中，使用随机向量替代\")\n",
    "\n",
    "        # 调整为128维（原模型为300维，截断或填充）\n",
    "        vec = vec[:128] if len(vec) >= 128 else np.pad(vec, (0, 128 - len(vec)), 'constant')\n",
    "        # 归一化到-1到1范围\n",
    "        vec = vec / np.max(np.abs(vec)) if np.max(np.abs(vec)) != 0 else vec\n",
    "        # 保留4位小数（与原需求一致）\n",
    "        vec = np.round(vec, 4)\n",
    "        embeddings.append(vec)\n",
    "        print(f\"成功生成变量「{var}」的Word2Vec语义向量（128维）\")\n",
    "\n",
    "    return {var: emb for var, emb in zip(vars_list, embeddings)}\n",
    "\n",
    "#  用KMeans进行聚类\n",
    "def clustering(causal_knowledge, var_embeddings, n_clusters=2):\n",
    "    pair_list = list(causal_knowledge.keys())\n",
    "    pair_features = []\n",
    "    for pair in pair_list:\n",
    "        x1, x2 = pair\n",
    "        if x1 not in var_embeddings or x2 not in var_embeddings:\n",
    "            raise ValueError(f\"变量{x1}/{x2}无语义向量，请先调用get_llm_embeddings\")\n",
    "        feat = (var_embeddings[x1] + var_embeddings[x2]) / 2\n",
    "        pair_features.append(feat)\n",
    "    pair_features = np.array(pair_features)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(pair_features)\n",
    "\n",
    "    cluster_to_pairs = {}\n",
    "    for pair, label in zip(pair_list, cluster_labels):\n",
    "        cluster_id = f\"S_{label+1}\"\n",
    "        if cluster_id not in cluster_to_pairs:\n",
    "            cluster_to_pairs[cluster_id] = []\n",
    "        cluster_to_pairs[cluster_id].append(pair)\n",
    "\n",
    "    print(f\"\\n=== 硬聚类结果（{n_clusters}个集合S） ===\")\n",
    "    for cluster_id, pairs in cluster_to_pairs.items():\n",
    "        print(f\"集合{cluster_id}（{len(pairs)}个变量对）：{pairs}\")\n",
    "    return cluster_to_pairs, {pair: f\"S_{label+1}\" for pair, label in zip(pair_list, cluster_labels)}\n",
    "\n",
    "class ClusterInfo:\n",
    "    \"\"\"封装聚类相关信息，用于alpha_calibrate函数调用\"\"\"\n",
    "    def __init__(self, cluster_to_pairs, pair_to_cluster, var_embeddings, N, alpha, perturbation_strength):\n",
    "        self.cluster_to_pairs = cluster_to_pairs  # {簇ID: [变量对列表]}\n",
    "        self.pair_to_cluster = pair_to_cluster  # {变量对: 簇ID}\n",
    "        self.var_embeddings = var_embeddings    # 变量语义向量（用于聚类验证）\n",
    "        self.N = N                              # 总变量对数量（universe大小）\n",
    "        self.alpha = alpha                      # 算法3.1的α参数\n",
    "        self.perturbation_strength = perturbation_strength  # 首次迭代扰动强度，仅用于此代码运行\n",
    "\n",
    "#这里应该是调用统计查询获得真实基准p*(S)的函数，这里仅供代码运行\n",
    "def statistical_query_oracle(\n",
    "    S_pairs: list,\n",
    "    prob_type: str,\n",
    "    causal_knowledge: dict,\n",
    "    tau: float,\n",
    "    N: int,\n",
    "    iteration: int,\n",
    "    perturbation_strength: float = 0.03\n",
    ") -> float:\n",
    "    \"\"\"算法3.1的统计查询接口：返回真实基准p*_S的近似值（含首次扰动）\"\"\"\n",
    "    # 基础值：原始概率的簇内均值\n",
    "    base_p_star_S = np.mean([causal_knowledge[pair][prob_type] for pair in S_pairs])\n",
    "    S_size = len(S_pairs)\n",
    "\n",
    "    # 首次迭代添加语义合理的扰动\n",
    "    if iteration == 1:\n",
    "        if prob_type == \"causal\":\n",
    "            perturbation = perturbation_strength if base_p_star_S > 0.5 else -perturbation_strength\n",
    "        elif prob_type == \"independent\":\n",
    "            perturbation = perturbation_strength if base_p_star_S > 0.5 else -perturbation_strength\n",
    "        else:\n",
    "            perturbation = np.random.choice([-perturbation_strength, perturbation_strength])\n",
    "        perturbed_p_star_S = np.clip(base_p_star_S + perturbation, 0.01, 0.99)\n",
    "        p_star_S = perturbed_p_star_S\n",
    "    else:\n",
    "        p_star_S = base_p_star_S\n",
    "\n",
    "    # 误差控制（符合算法3.1的统计查询容忍度）\n",
    "    max_error = tau * N / S_size\n",
    "    error = np.random.uniform(-max_error, max_error)\n",
    "    p_star_S_with_error = np.clip(p_star_S + error, 0.01, 0.99)\n",
    "\n",
    "    return p_star_S_with_error\n",
    "\n",
    "\n",
    "def multi_calibration(\n",
    "    causal_knowledge: dict,\n",
    "    n_clusters: int = 2,\n",
    "    alpha: float = 0.05,\n",
    "    max_iter: int = 1000,\n",
    "    perturbation_strength: float = 0.03\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    使用校准函数调整推导的因果概率，确保与真实的因果关系匹配\n",
    "    校准过程：\n",
    "    - 使用嵌入的语义向量对因果知识进行硬聚类；\n",
    "    - 迭代调用alpha_calibrate，对每种概率类型分簇校准；\n",
    "    - 归一化概率，确保三种概率之和为1。\n",
    "    \n",
    "    输入：\n",
    "    - causal_knowledge: LLM生成的因果知识字典，格式：\n",
    "      {\n",
    "          ('X1', 'X2'): {\n",
    "              'independent': p_independent,\n",
    "              'latent': p_latent,\n",
    "              'causal': p_causal\n",
    "          },\n",
    "          ...\n",
    "      }\n",
    "    - n_clusters: 硬聚类的簇数（默认2）\n",
    "    - alpha: 校准精度参数（默认0.05）\n",
    "    - max_iter: 最大迭代次数（默认1000）\n",
    "    - perturbation_strength: 首次迭代的扰动强度（默认0.03）\n",
    "    \n",
    "    输出：\n",
    "    - calibrated_probabilities: 校准后的因果概率字典（格式与输入一致）\n",
    "    \"\"\"\n",
    "    # 生成所有变量的语义向量（聚类依赖）\n",
    "    print(\"=== 生成变量语义向量 ===\")\n",
    "    all_vars = list(set([var for pair in causal_knowledge.keys() for var in pair]))\n",
    "    var_embeddings = get_word2vec_embeddings(all_vars)\n",
    "\n",
    "    # 对变量对进行硬聚类（划分簇S）\n",
    "    print(\"\\n=== 步骤2：对变量对进行硬聚类 ===\")\n",
    "    cluster_to_pairs, pair_to_cluster = clustering(\n",
    "        causal_knowledge=causal_knowledge,\n",
    "        var_embeddings=var_embeddings,\n",
    "        n_clusters=n_clusters\n",
    "    )\n",
    "\n",
    "    # 初始化参数与ClusterInfo对象（封装聚类信息）\n",
    "    N = len(causal_knowledge)  # 总变量对数量\n",
    "    cluster_info = ClusterInfo(\n",
    "        cluster_to_pairs=cluster_to_pairs,\n",
    "        pair_to_cluster=pair_to_cluster,\n",
    "        var_embeddings=var_embeddings,\n",
    "        N=N,\n",
    "        alpha=alpha,\n",
    "        perturbation_strength=perturbation_strength\n",
    "    )\n",
    "    calibrated_probabilities = {pair: prob.copy() for pair, prob in causal_knowledge.items()}\n",
    "    updated = True\n",
    "    iteration = 0\n",
    "\n",
    "    # 迭代调用alpha_calibrate进行多校准\n",
    "    print(\"\\n=== 步骤3：迭代执行α校准 ===\")\n",
    "    while updated and iteration < max_iter:\n",
    "        updated = False\n",
    "        iteration += 1\n",
    "        print(f\"\\n=== 迭代{iteration}/{max_iter} ===\")\n",
    "\n",
    "        # 遍历所有变量对，对每种概率类型调用alpha_calibrate\n",
    "        temp_calibrated = calibrated_probabilities.copy()  # 临时存储本轮更新结果（避免迭代中相互影响）\n",
    "        for pair, probabilities in calibrated_probabilities.items():\n",
    "            # 对三种概率类型分别校准\n",
    "            for prob_type in ['independent', 'latent', 'causal']:\n",
    "                original_prob = probabilities[prob_type]\n",
    "                # 调用alpha_calibrate进行校准\n",
    "                calibrated_prob = alpha_calibrate(\n",
    "                    probability=original_prob,\n",
    "                    pair=pair,\n",
    "                    prob_type=prob_type,\n",
    "                    causal_knowledge=causal_knowledge,\n",
    "                    cluster_info=cluster_info,\n",
    "                    iteration=iteration,\n",
    "                    calibrated_probs=calibrated_probabilities  # 传入当前所有校准概率，用于计算x_S\n",
    "                )\n",
    "                # 暂存校准结果（本轮内不覆盖，避免影响其他变量对的x_S计算）\n",
    "                temp_calibrated[pair][prob_type] = calibrated_prob\n",
    "                # 若有更新，标记本轮为更新状态\n",
    "                if abs(calibrated_prob - original_prob) > 1e-6:  # 忽略微小浮点误差\n",
    "                    updated = True\n",
    "\n",
    "        # 更新校准概率，并对每个变量对的概率归一化（确保和为1）\n",
    "        for pair in temp_calibrated:\n",
    "            total = sum(temp_calibrated[pair].values())\n",
    "            if total > 0:\n",
    "                temp_calibrated[pair] = {\n",
    "                    k: round(v / total, 3)\n",
    "                    for k, v in temp_calibrated[pair].items()\n",
    "                }\n",
    "        calibrated_probabilities = temp_calibrated\n",
    "\n",
    "    # 输出迭代终止信息\n",
    "    print(f\"\\n=== 迭代终止 ===\")\n",
    "    print(f\"总迭代次数：{iteration}次（{'已收敛' if not updated else '达到最大迭代次数'}）\")\n",
    "    return calibrated_probabilities\n",
    "\n",
    "# 校准函数，模拟alpha校准效果\n",
    "def alpha_calibrate(\n",
    "    probability: float,\n",
    "    pair: tuple,\n",
    "    prob_type: str,\n",
    "    causal_knowledge: dict,\n",
    "    cluster_info: ClusterInfo,\n",
    "    iteration: int,\n",
    "    calibrated_probs: dict\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    算法3.1的α校准核心逻辑：\n",
    "    1. 根据变量对所属簇，获取簇内信息；\n",
    "    2. 调用统计查询获取真实基准p*_S；\n",
    "    3. 计算当前簇内预测均值x_S，判断偏差是否超阈值；\n",
    "    4. 超阈值则更新概率，返回校准后的值。\n",
    "    \"\"\"\n",
    "    # 获取当前变量对的簇信息\n",
    "    cluster_id = cluster_info.pair_to_cluster[pair]\n",
    "    S_pairs = cluster_info.cluster_to_pairs[cluster_id]  # 簇内所有变量对\n",
    "    S_size = len(S_pairs)\n",
    "    N = cluster_info.N\n",
    "    alpha = cluster_info.alpha\n",
    "    perturbation_strength = cluster_info.perturbation_strength\n",
    "\n",
    "    # 计算算法3.1的关键参数\n",
    "    gamma = S_size / N\n",
    "    tau = alpha * gamma / 4  # 统计查询容忍度\n",
    "    threshold = alpha * S_size - tau * N  # 偏差阈值\n",
    "\n",
    "    # 调用统计查询获取真实基准p*_S\n",
    "    p_star_S = statistical_query_oracle(\n",
    "        S_pairs=S_pairs,\n",
    "        prob_type=prob_type,\n",
    "        causal_knowledge=causal_knowledge,\n",
    "        tau=tau,\n",
    "        N=N,\n",
    "        iteration=iteration,\n",
    "        perturbation_strength=perturbation_strength\n",
    "    )\n",
    "\n",
    "    # 计算当前簇内预测均值x_S（基于所有变量对的当前校准概率）\n",
    "    x_S = np.mean([calibrated_probs[pair_in_S][prob_type] for pair_in_S in S_pairs])\n",
    "\n",
    "    # 计算偏差并判断是否更新\n",
    "    delta_S = p_star_S - x_S\n",
    "    print(f\"簇{cluster_id}（{prob_type}）：变量对{pair} → x_S={x_S:.3f}，ΔS={delta_S:.3f}，阈值={threshold:.3f}\")\n",
    "\n",
    "    if abs(delta_S) > threshold:\n",
    "        # 偏差超阈值，计算更新步长（均匀分配到簇内所有变量对）\n",
    "        update_step = delta_S / S_size\n",
    "        calibrated_prob = probability + update_step\n",
    "        print(f\"簇{cluster_id}（{prob_type}）：变量对{pair} → 原始={probability:.3f}，更新={update_step:.4f}\")\n",
    "    else:\n",
    "        # 偏差未超阈值，不更新\n",
    "        calibrated_prob = probability\n",
    "        print(f\"簇{cluster_id}（{prob_type}）：变量对{pair} → 偏差未超阈值，不更新\")\n",
    "\n",
    "    # 确保概率在[0.01, 0.99]范围内（避免极端值）\n",
    "    calibrated_prob = max(0.01, min(calibrated_prob, 0.99))\n",
    "    return calibrated_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e2c25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: 形成先验因果图\n",
    "def create_prior_causal_graph(calibrated_probabilities):\n",
    "    \"\"\"\n",
    "    根据校准后的因果概率生成先验因果图\n",
    "    - 使用三个概率判断每对变量之间的因果关系（独立性、潜在混杂变量、因果方向）。\n",
    "    - 根据综合判断结果生成因果图，可能会有双向箭头（<->）表示不确定或相互作用。\n",
    "    \n",
    "    输入：\n",
    "    - calibrated_probabilities: 每对变量的校准后概率字典，\n",
    "        格式：{\n",
    "            ('X1', 'X2'): {\n",
    "                'independent': p_independent,\n",
    "                'latent': p_latent,\n",
    "                'causal': p_causal\n",
    "            },\n",
    "            ...\n",
    "        }\n",
    "    输出：\n",
    "    - prior_graph: 先验因果图，格式为字典，键是变量对，值是因果关系（X->Y, Y->X, <->, independent）\n",
    "    \"\"\"\n",
    "    prior_graph = {}\n",
    "    \n",
    "    # 遍历每对变量，判断因果关系\n",
    "    for pair, probabilities in calibrated_probabilities.items():\n",
    "        p_independent = probabilities['independent']  # 独立性概率\n",
    "        p_latent = probabilities['latent']  # 潜在混杂变量概率\n",
    "        p_causal = probabilities['causal']  # 因果方向概率\n",
    "        \n",
    "        # 判断因果关系\n",
    "        if p_independent > 0.5:\n",
    "            # 如果独立性概率大于0.5，认为X1和X2是独立的\n",
    "            prior_graph[pair] = \"independent\"\n",
    "        elif p_latent > 0.5:\n",
    "            # 如果潜在混杂变量概率大于0.5，认为存在潜在混杂变量\n",
    "            prior_graph[pair] = \"<->\"  # 双向箭头表示不确定或相互作用\n",
    "        else:\n",
    "            # 根据因果关系概率判断因果方向\n",
    "            if p_causal > 0.5:\n",
    "                # 如果因果概率大于0.5，认为X1导致X2\n",
    "                prior_graph[pair] = f\"{pair[0]}->{pair[1]}\"\n",
    "            elif p_causal < 0.5:\n",
    "                # 如果因果概率小于0.5，认为X2导致X1\n",
    "                prior_graph[pair] = f\"{pair[1]}->{pair[0]}\"\n",
    "            else:\n",
    "                # 如果因果概率接近0.5，认为两者之间相互作用\n",
    "                prior_graph[pair] = \"<->\"\n",
    "    \n",
    "    return prior_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3566bb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: 使用BCCD结合数据生成后验因果图\n",
    "def generate_post_causal_graph(prior_graph, data):\n",
    "    \"\"\"\n",
    "    使用BCCD（贝叶斯因果链发现）结合数据生成后验因果图\n",
    "    - 结合先验因果图和实际数据，推导出后验因果关系。\n",
    "    - 应用约束（如无环性约束），确保生成的因果图合理。\n",
    "    \n",
    "    输入：先验因果图、数据\n",
    "    输出：后验因果图（推导出的因果关系图，满足约束条件）\n",
    "    \"\"\"\n",
    "    # 将先验因果图应用于数据，使用BCCD进一步推导因果关系\n",
    "    post_causal_graph = bccd_inference(data, prior_graph)\n",
    "    \n",
    "    # 对后验图进行约束，确保没有环路等不合理的因果关系\n",
    "    post_causal_graph = apply_constraints(post_causal_graph)\n",
    "    \n",
    "    return post_causal_graph\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
