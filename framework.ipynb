{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a383715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import math\n",
    "import re\n",
    "\n",
    "client = openai.OpenAI(\n",
    "    api_key=\"\",  \n",
    "    base_url=\"https://llmapi.paratera.com/v1/\"  # 建议带上 https://\n",
    ")\n",
    "\n",
    "# === 工具函数 ===\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "def parse_probabilities(llm_output: str):\n",
    "    \"\"\"\n",
    "    从 LLM 文本输出中提取概率。\n",
    "    比如：\n",
    "    P(yes) = 0.0  \n",
    "    P(no) = 1.0\n",
    "    \"\"\"\n",
    "    matches = re.findall(r\"([0-9]*\\.?[0-9]+)\", llm_output)\n",
    "    if len(matches) >= 2:\n",
    "        p1, p2 = float(matches[0]), float(matches[1])\n",
    "        total = p1 + p2\n",
    "        if total == 0:\n",
    "            return 0.5, 0.5\n",
    "        return p1 / total, p2 / total\n",
    "    return 0.5, 0.5  # fallback\n",
    "\n",
    "def parse_logits(llm_output: str):\n",
    "    matches = re.findall(r\"([-]?[0-9]*\\.?[0-9]+)\", llm_output)\n",
    "    if len(matches) >= 2:\n",
    "        l1, l2 = float(matches[0]), float(matches[1])\n",
    "        if not math.isclose(l1 + l2, 0):\n",
    "            avg = (l1 - l2) / 2\n",
    "            l1, l2 = avg, -avg\n",
    "        return l1, l2\n",
    "    return 0.0, 0.0\n",
    "\n",
    "def llm_judge_openai(prompt, x1, x2, method='probability', n_sample=10):\n",
    "    \"\"\"\n",
    "    使用 client.chat.completions.create\n",
    "    method: 'frequency' | 'probability' | 'logit'\n",
    "    返回: {\"label\": 1或0, \"prob\": 最大概率}\n",
    "    \"\"\"\n",
    "\n",
    "    if method == 'frequency':\n",
    "        votes = []\n",
    "        for _ in range(n_sample):\n",
    "            resp = client.chat.completions.create(\n",
    "                model=\"DeepSeek-R1-0528\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                max_tokens=50,\n",
    "                temperature=0.7,\n",
    "            )\n",
    "            text = resp.choices[0].message.content.strip()\n",
    "            votes.append(1 if text.lower().startswith(\"yes\") else 0)\n",
    "\n",
    "        p_yes = sum(votes) / len(votes)\n",
    "        p_no = 1 - p_yes\n",
    "        # 取最大标签与其概率（平局默认选 yes=>1）\n",
    "        if p_yes >= p_no:\n",
    "            return {\"label\": 1, \"prob\": p_yes}\n",
    "        else:\n",
    "            return {\"label\": 0, \"prob\": p_no}\n",
    "\n",
    "    elif method == 'probability':\n",
    "        resp = client.chat.completions.create(\n",
    "            model=\"DeepSeek-R1-0528\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=200,\n",
    "            temperature=0.7,\n",
    "        )\n",
    "        text = resp.choices[0].message.content.strip()\n",
    "        print(\"LLM 原始输出：\\n\", text)  # 调试用\n",
    "\n",
    "        p_yes, p_no = parse_probabilities(text)\n",
    "        if p_yes >= p_no:\n",
    "            return {\"label\": 1, \"prob\": p_yes}\n",
    "        else:\n",
    "            return {\"label\": 0, \"prob\": p_no}\n",
    "\n",
    "    elif method == 'logit':\n",
    "        resp = client.chat.completions.create(\n",
    "            model=\"DeepSeek-R1-0528\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=200,\n",
    "            temperature=0.7,\n",
    "        )\n",
    "        text = resp.choices[0].message.content.strip()\n",
    "        logit_yes, logit_no = parse_logits(text)\n",
    "        p_yes = sigmoid(logit_yes)\n",
    "        p_no = sigmoid(logit_no)\n",
    "\n",
    "        if p_yes >= p_no:\n",
    "            return {\"label\": 1, \"prob\": p_yes}\n",
    "        else:\n",
    "            return {\"label\": 0, \"prob\": p_no}\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Method should be one of 'frequency', 'probability', or 'logit'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "256cddd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_backdoor(x1, x2, method='logit'):\n",
    "    prompt = f\"请判断 {x1} 与 {x2} 之间是否存在 back-door path。\" \\\n",
    "             f\"请直接输出概率或 logit，并确保满足 Kolmogorov 公理（或 logit1 + logit2 = 0）。\"\n",
    "    return llm_judge_openai(prompt, x1, x2, method)\n",
    "\n",
    "def check_independence_after_block(x1, x2, method='logit'):\n",
    "    prompt = f\"阻断 back-door path 后，{x1} 与 {x2} 是否独立？\" \\\n",
    "             f\"请输出概率对或 logit，并确保满足 Kolmogorov 公理（或 logit1 + logit2 = 0）。\"\n",
    "    return llm_judge_openai(prompt, x1, x2, method)\n",
    "\n",
    "def check_latent_confounder_after_block(x1, x2, method='logit'):\n",
    "    prompt = f\"阻断 back-door path 后，{x1} 与 {x2} 是否存在潜在混杂因子？\" \\\n",
    "             f\"请输出概率对或 logit，并确保满足 Kolmogorov 公理（或 logit1 + logit2 = 0）。\"\n",
    "    return llm_judge_openai(prompt, x1, x2, method)\n",
    "\n",
    "def check_causal_direction_after_block(x1, x2, method='logit'):\n",
    "    prompt = f\"阻断 back-door path 后，请判断 {x1} 是否会导致 {x2}。\" \\\n",
    "             f\"请输出概率对或 logit，并确保满足 Kolmogorov 公理（或 logit1 + logit2 = 0）。\"\n",
    "    return llm_judge_openai(prompt, x1, x2, method)\n",
    "\n",
    "def check_independence(x1, x2, method='logit'):\n",
    "    prompt = f\"请判断 {x1} 与 {x2} 是否独立。\" \\\n",
    "             f\"请输出概率或 logit，并确保满足 Kolmogorov 公理（或 logit1 + logit2 = 0）。\"\n",
    "    return llm_judge_openai(prompt, x1, x2, method)\n",
    "\n",
    "def check_latent_confounder(x1, x2, method='logit'):\n",
    "    prompt = f\"请判断 {x1} 与 {x2} 之间是否存在潜在混杂因子。\" \\\n",
    "             f\"请输出概率或 logit，并确保满足 Kolmogorov 公理（或 logit1 + logit2 = 0）。\"\n",
    "    return llm_judge_openai(prompt, x1, x2, method)\n",
    "\n",
    "def check_causal_direction(x1, x2, method='logit'):\n",
    "    prompt = f\"请判断 {x1} 是否会导致 {x2}。\" \\\n",
    "             f\"请输出概率或 logit，并确保满足 Kolmogorov 公理（或 logit1 + logit2 = 0）。\"\n",
    "    return llm_judge_openai(prompt, x1, x2, method)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ec3d40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM 原始输出：\n",
      " 在标准因果推断框架下，针对变量 \"age\" 和 \"blood pressure\"，我们考虑一个常见的因果图模型。通常，\"age\" 被视为一个外生变量（没有指向它的箭头），而 \"blood pressure\" 是结果变量。如果因果图中仅包含从 \"age\" 到 \"blood pressure\" 的直接路径（即 age → blood pressure），并且没有其他变量（如混杂因素）连接两者，则不存在后门路径（back-door path）。后门路径要求路径中包含指向 \"age\" 的箭头，但作为外生变量，\"age\" 没有此类路径。\n",
      "\n",
      "基于医学和因果推断的常见知识，在缺乏额外变量（如遗传或生活方式因素）的简单模型中，\"age\" 和 \"blood pressure\" 之间通常不存在后门路径。因此，我们判断后门路径存在的概率较低。\n",
      "\n",
      "为满足问题要求，输出概率并确保 Kolmogorov 公理（概率非负且和为1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'label': 1, 'prob': 0.5}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_backdoor('age', 'blood presure', method='probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18f0599d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: LLM 生成因果知识\n",
    "def tree_query(x1, x2, method='probability'):\n",
    "    \"\"\"\n",
    "    基于树状逻辑的因果方向查询器（不做阈值判断）。\n",
    "    每一步子检查函数都返回: {\"label\": 1或0, \"prob\": float}\n",
    "\n",
    "    输出:\n",
    "        {\n",
    "            'relation': 'x->y' | 'y->x' | 'x<->y' | 'independent',\n",
    "            'confidence': float,   # 取决定该结论的那一步的 prob\n",
    "            'log': [(step_name, {'label': int, 'prob': float}), ...]\n",
    "        }\n",
    "    \"\"\"\n",
    "    log = []\n",
    "\n",
    "    # Step 1: 是否存在 backdoor path?\n",
    "    res_backdoor = check_backdoor(x1, x2, method)\n",
    "    log.append((\"backdoor_path\", res_backdoor))\n",
    "\n",
    "    if res_backdoor[\"label\"] == 1:\n",
    "        # Step 2: 阻断路径后是否独立？\n",
    "        res_ind = check_independence_after_block(x1, x2, method)\n",
    "        log.append((\"independent_after_block\", res_ind))\n",
    "        if res_ind[\"label\"] == 1:\n",
    "            return {\"relation\": \"independent\", \"confidence\": res_ind[\"prob\"], \"log\": log}\n",
    "\n",
    "        # Step 3: 是否存在潜在混杂因子？\n",
    "        res_latent = check_latent_confounder_after_block(x1, x2, method)\n",
    "        log.append((\"latent_confounder_after_block\", res_latent))\n",
    "        if res_latent[\"label\"] == 1:\n",
    "            return {\"relation\": \"x<->y\", \"confidence\": res_latent[\"prob\"], \"log\": log}\n",
    "\n",
    "        # Step 4: 判断方向 (x→y?)\n",
    "        res_dir = check_causal_direction_after_block(x1, x2, method)\n",
    "        log.append((\"x->y_after_block\", res_dir))\n",
    "        if res_dir[\"label\"] == 1:\n",
    "            return {\"relation\": \"x->y\", \"confidence\": res_dir[\"prob\"], \"log\": log}\n",
    "        else:\n",
    "            return {\"relation\": \"y->x\", \"confidence\": res_dir[\"prob\"], \"log\": log}\n",
    "\n",
    "    else:\n",
    "        # 不存在 backdoor path\n",
    "        res_ind = check_independence(x1, x2, method)\n",
    "        log.append((\"independent_no_backdoor\", res_ind))\n",
    "        if res_ind[\"label\"] == 1:\n",
    "            return {\"relation\": \"independent\", \"confidence\": res_ind[\"prob\"], \"log\": log}\n",
    "\n",
    "        res_latent = check_latent_confounder(x1, x2, method)\n",
    "        log.append((\"latent_confounder_no_backdoor\", res_latent))\n",
    "        if res_latent[\"label\"] == 1:\n",
    "            return {\"relation\": \"x<->y\", \"confidence\": res_latent[\"prob\"], \"log\": log}\n",
    "\n",
    "        res_dir = check_causal_direction(x1, x2, method)\n",
    "        log.append((\"x->y_no_backdoor\", res_dir))\n",
    "        if res_dir[\"label\"] == 1:\n",
    "            return {\"relation\": \"x->y\", \"confidence\": res_dir[\"prob\"], \"log\": log}\n",
    "        else:\n",
    "            return {\"relation\": \"y->x\", \"confidence\": res_dir[\"prob\"], \"log\": log}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59873785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM 原始输出：\n",
      " 1.0\n",
      "LLM 原始输出：\n",
      " 在因果推断中，溺水人数（Drowning）与冰淇淋销量（Ice Cream Sales）之间的关联通常由混杂因子（如温度，Temperature）引起，而非直接因果关系。当阻断 back-door path（即控制混杂因子温度）后，溺水人数与冰淇淋销量在给定温度的条件下应满足条件独立。这是因为在控制温度后，两者之间的伪相关被消除，仅剩下随机变异。\n",
      "\n",
      "### 是否独立？\n",
      "是的，阻断 back-door path（控制温度）后，溺水人数与冰淇淋销量条件独立。即：\n",
      "\\[\n",
      "P(\\text{Drowning} \\mid \\text{Ice Cream Sales}, \\text{Temperature}) = P(\\text{Drowning} \\mid \\text{Temperature})\n",
      "\\]\n",
      "或等价地，联合概率满足：\n",
      "\\[\n",
      "P(\\text{Drowning}, \\text{Ice Cream Sales} \\mid \\text{Temperature}) = P(\\text{Drowning} \\mid \\text{Temperature}) \\times P(\\text{Ice\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'relation': 'independent',\n",
       " 'confidence': 0.5,\n",
       " 'log': [('backdoor_path', {'label': 1, 'prob': 0.5}),\n",
       "  ('independent_after_block', {'label': 1, 'prob': 0.5})]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_query('溺水人数', '冰淇淋销量', method='probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc47fbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM 原始输出：\n",
      " 在因果推断中，back-door path 是指从原因变量到结果变量的一条路径，该路径以指向原因变量的箭头开头（例如，通过一个共同原因或混淆变量）。对于“闪电”（lightning）和“打雷”（thunder）之间的关系：\n",
      "\n",
      "- 闪电是打雷的直接原因（闪电产生声波，即打雷），因此在基本因果图中，路径为 Lightning → Thunder。\n",
      "- 如果考虑更完整的模型，雷暴云（积雨云）作为共同原因，因果图可能为 Storm Cloud → Lightning → Thunder（即雷暴云导致闪电，闪电导致打雷）。在这个图中，从 Lightning 到 Thunder 的路径只有一条：Lightning → Thunder（前门路径）。没有以指向 Lightning 的箭头开头的路径（即没有如 Lightning ← Storm Cloud → Thunder 的有效路径，因为路径中节点不能重复，且没有直接的 Storm Cloud → Thunder 路径）。\n",
      "\n",
      "因此，在 Lightning 和 Thunder\n",
      "LLM 原始输出：\n",
      " 在因果推断中，阻断后门路径（back-door path）的目的是消除混杂偏倚（confounding bias），从而允许估计变量间的因果效应，但并不意味着变量之间会变得独立。闪电（Lightning）和打雷（Thunder）之间存在直接的因果路径（闪电导致打雷），因此即使在阻断后门路径后（例如，通过条件化在混杂变量上），闪电和打雷也不会独立。它们仍然由于直接因果效应而相关。\n",
      "\n",
      "### 原因分析：\n",
      "- 典型的因果图中，闪电（L）和打雷（T）可能受一个混杂变量（如风暴，Storm，记为 S）影响。因果路径为：\n",
      "  - \\(S \\rightarrow L\\)\n",
      "  - \\(S \\rightarrow T\\)\n",
      "  - \\(L \\rightarrow T\\)\n",
      "- 后门路径为 \\(L \\leftarrow S \\rightarrow T\\)。阻断此路径（例如，通过条件化在 S 上）后，混杂效应\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'relation': 'independent',\n",
       " 'confidence': 0.5,\n",
       " 'log': [('backdoor_path', {'label': 1, 'prob': 0.5}),\n",
       "  ('independent_after_block', {'label': 1, 'prob': 0.5})]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_query('闪电', '打雷', method='probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0944f774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM 原始输出：\n",
      " 3\n",
      "LLM 原始输出：\n",
      " 阻断 back-door path 后，教育年限与收入水平不独立。原因在于，back-door path 的阻断消除了混杂变量的影响（如家庭背景或个人能力），从而允许教育年限对收入水平的因果效应显现。教育年限通常对收入水平有积极影响（例如，更高教育年限往往导致更高收入），因此两个变量在条件分布下相关，而非独立。\n",
      "\n",
      "由于问题要求输出概率对或 logit，并满足 Kolmogorov 公理（概率和为1）或 logit 和为零，我将基于标准因果推断模型提供一个简单示例。假设收入水平是二元的（0 = 低收入, 1 = 高收入），教育年限为连续变量，但在输出时需固定一个教育年限值以计算具体概率。这里，我假设教育年限 = 12 年（典型高中毕业年限），并基于常见实证研究（如 Mincer 方程）设定参数，确保输出符合要求。\n",
      "\n",
      "### 输出概率对\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'relation': 'independent',\n",
       " 'confidence': 1.0,\n",
       " 'log': [('backdoor_path', {'label': 1, 'prob': 0.5}),\n",
       "  ('independent_after_block', {'label': 1, 'prob': 1.0})]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_query('教育年限', '收入水平', method='probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a47f78f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM 原始输出：\n",
      " 1.386, -1.386\n",
      "LLM 原始输出：\n",
      " 在因果推断中，阻断 back-door path（后门路径）通常是通过条件在混杂变量（confounder）上来实现，以消除混杂偏差，从而准确估计氟化物（F）对蛀牙（C）的因果效应。在标准因果图（例如，氟化物 → 蛀牙，并有混杂变量 U，如社会经济状态（SES），其中 U → 氟化物 和 U → 蛀牙）中，阻断 back-door path（例如，通过条件在 U 上）后，氟化物与蛀牙之间仍存在直接因果路径（氟化物 → 蛀牙）。因此，氟化物与蛀牙在条件上（给定 U）并不独立，除非因果效应为零（即氟化物对蛀牙无影响）。在现实中，氟化物通常被认为能减少蛀牙风险，因此因果效应存在，独立性不成立。\n",
      "\n",
      "### 回答：\n",
      "- **是否独立？** 否，阻断 back-door path 后\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'relation': 'independent',\n",
       " 'confidence': 0.5,\n",
       " 'log': [('backdoor_path', {'label': 1, 'prob': 0.5}),\n",
       "  ('independent_after_block', {'label': 1, 'prob': 0.5})]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_query('氟化物','蛀牙', method='probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03734d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: 多校准 (multi-Calibration)\n",
    "def multi_calibration(causal_knowledge):\n",
    "    \"\"\"\n",
    "    使用校准函数调整推导的因果概率，确保与真实的因果关系匹配\n",
    "    校准过程：\n",
    "    - 使用嵌入的语义向量对因果知识进行聚类，或者按节点相关边划分类。\n",
    "    - 然后，进行alpha校准，调整因果概率以确保模型输出更准确。\n",
    "    \n",
    "    输入：\n",
    "    - causal_knowledge: LLM生成的因果知识字典，每对变量的因果关系概率，\n",
    "      格式：\n",
    "      {\n",
    "          ('X1', 'X2'): {\n",
    "              'independent': p_independent,\n",
    "              'latent': p_latent,\n",
    "              'causal': p_causal\n",
    "          },\n",
    "          ...\n",
    "      }\n",
    "    \n",
    "    输出：\n",
    "    - calibrated_probabilities: 校准后的因果概率字典，格式和输入一样\n",
    "    \"\"\"\n",
    "    \n",
    "    # 确定合适的划分准则，例如基于嵌入的语义向量进行聚类，或按节点相关边进行分类\n",
    "    clusters = clustering(causal_knowledge)\n",
    "    \n",
    "    # 校准函数 - alpha校准\n",
    "    # 需要对每对变量的概率（'independent', 'latent', 'causal'）进行alpha校准\n",
    "    calibrated_probabilities = {}\n",
    "    for pair, probabilities in causal_knowledge.items():\n",
    "        p_independent = probabilities['independent']\n",
    "        p_latent = probabilities['latent']\n",
    "        p_causal = probabilities['causal']\n",
    "        \n",
    "        # 校准因果概率（模拟alpha校准的效果）\n",
    "        calibrated_p_independent = alpha_calibrate(p_independent, clusters)\n",
    "        calibrated_p_latent = alpha_calibrate(p_latent, clusters)\n",
    "        calibrated_p_causal = alpha_calibrate(p_causal, clusters)\n",
    "        \n",
    "        # 存储校准后的概率\n",
    "        calibrated_probabilities[pair] = {\n",
    "            'independent': calibrated_p_independent,\n",
    "            'latent': calibrated_p_latent,\n",
    "            'causal': calibrated_p_causal\n",
    "        }\n",
    "    \n",
    "    return calibrated_probabilities\n",
    "\n",
    "# 校准函数，模拟alpha校准效果（可根据实际需求调整）\n",
    "def alpha_calibrate(probability, clusters):\n",
    "    \"\"\"\n",
    "    模拟alpha校准：通过校准函数对因果概率进行调整，具体的校准方法可以根据需要实现。\n",
    "    \n",
    "    输入：\n",
    "    - probability: 需要校准的因果概率\n",
    "    - clusters: 聚类后的信息，用于调整概率\n",
    "    \n",
    "    输出：\n",
    "    - calibrated_probability: 校准后的因果概率\n",
    "    \"\"\"\n",
    "    # 这里使用简单的比例调整作为示例，可以根据具体的alpha校准算法进行调整\n",
    "    # 假设根据聚类结果调整因果概率\n",
    "    adjustment_factor = 1.0  # 可以根据聚类的情况进行调整\n",
    "    calibrated_probability = probability * adjustment_factor\n",
    "    \n",
    "    # 确保概率在[0, 1]范围内\n",
    "    calibrated_probability = max(0.0, min(calibrated_probability, 1.0))\n",
    "    \n",
    "    return calibrated_probability\n",
    "\n",
    "# 示例聚类函数（此处为简单的示例，实际聚类方法可能涉及更多细节）\n",
    "def clustering(causal_knowledge):\n",
    "    \"\"\"\n",
    "    聚类函数：根据因果关系知识对变量进行聚类\n",
    "    这里仅是示例，实际聚类可以通过语义向量、相关性或其他方式进行。\n",
    "    \"\"\"\n",
    "    clusters = {}  # 模拟聚类结果，实际应使用有效的聚类方法\n",
    "    for pair in causal_knowledge:\n",
    "        clusters[pair] = \"cluster_1\"  # 假设所有变量对属于同一簇\n",
    "    return clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e2c25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: 形成先验因果图\n",
    "def create_prior_causal_graph(calibrated_probabilities):\n",
    "    \"\"\"\n",
    "    根据校准后的因果概率生成先验因果图\n",
    "    - 使用三个概率判断每对变量之间的因果关系（独立性、潜在混杂变量、因果方向）。\n",
    "    - 根据综合判断结果生成因果图，可能会有双向箭头（<->）表示不确定或相互作用。\n",
    "    \n",
    "    输入：\n",
    "    - calibrated_probabilities: 每对变量的校准后概率字典，\n",
    "        格式：{\n",
    "            ('X1', 'X2'): {\n",
    "                'independent': p_independent,\n",
    "                'latent': p_latent,\n",
    "                'causal': p_causal\n",
    "            },\n",
    "            ...\n",
    "        }\n",
    "    输出：\n",
    "    - prior_graph: 先验因果图，格式为字典，键是变量对，值是因果关系（X->Y, Y->X, <->, independent）\n",
    "    \"\"\"\n",
    "    prior_graph = {}\n",
    "    \n",
    "    # 遍历每对变量，判断因果关系\n",
    "    for pair, probabilities in calibrated_probabilities.items():\n",
    "        p_independent = probabilities['independent']  # 独立性概率\n",
    "        p_latent = probabilities['latent']  # 潜在混杂变量概率\n",
    "        p_causal = probabilities['causal']  # 因果方向概率\n",
    "        \n",
    "        # 判断因果关系\n",
    "        if p_independent > 0.5:\n",
    "            # 如果独立性概率大于0.5，认为X1和X2是独立的\n",
    "            prior_graph[pair] = \"independent\"\n",
    "        elif p_latent > 0.5:\n",
    "            # 如果潜在混杂变量概率大于0.5，认为存在潜在混杂变量\n",
    "            prior_graph[pair] = \"<->\"  # 双向箭头表示不确定或相互作用\n",
    "        else:\n",
    "            # 根据因果关系概率判断因果方向\n",
    "            if p_causal > 0.5:\n",
    "                # 如果因果概率大于0.5，认为X1导致X2\n",
    "                prior_graph[pair] = f\"{pair[0]}->{pair[1]}\"\n",
    "            elif p_causal < 0.5:\n",
    "                # 如果因果概率小于0.5，认为X2导致X1\n",
    "                prior_graph[pair] = f\"{pair[1]}->{pair[0]}\"\n",
    "            else:\n",
    "                # 如果因果概率接近0.5，认为两者之间相互作用\n",
    "                prior_graph[pair] = \"<->\"\n",
    "    \n",
    "    return prior_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3566bb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: 使用BCCD结合数据生成后验因果图\n",
    "def generate_post_causal_graph(prior_graph, data):\n",
    "    \"\"\"\n",
    "    使用BCCD（贝叶斯因果链发现）结合数据生成后验因果图\n",
    "    - 结合先验因果图和实际数据，推导出后验因果关系。\n",
    "    - 应用约束（如无环性约束），确保生成的因果图合理。\n",
    "    \n",
    "    输入：先验因果图、数据\n",
    "    输出：后验因果图（推导出的因果关系图，满足约束条件）\n",
    "    \"\"\"\n",
    "    # 将先验因果图应用于数据，使用BCCD进一步推导因果关系\n",
    "    post_causal_graph = bccd_inference(data, prior_graph)\n",
    "    \n",
    "    # 对后验图进行约束，确保没有环路等不合理的因果关系\n",
    "    post_causal_graph = apply_constraints(post_causal_graph)\n",
    "    \n",
    "    return post_causal_graph\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
