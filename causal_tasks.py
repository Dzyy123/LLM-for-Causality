"""
Causal Task Orchestrators Module

Defines task orchestrators for different types of causal inference analyses.
"""

from typing import List, Dict, Any, Tuple, Union
from itertools import combinations
from llm_utils import LocalLLMClient, OnlineLLMClient
from tree_query import (
    BackdoorPathExpert,
    IndependenceExpert,
    LatentConfounderExpert,
    CausalDirectionExpert,
    ExpertRouter,
    aggregate_expert_results
)
from tree_query.experts import BaseExpert


class CausalInferenceTask:
    """Base class for causal inference tasks using MoE architecture."""
    
    def __init__(
        self,
        client: Union[LocalLLMClient, OnlineLLMClient],
        all_variables: List[str]
    ):
        """
        Initialize the task.
        
        Args:
            client: LLM client for experts
            all_variables: List of all variables in the system
        """
        self.client = client
        self.all_variables = all_variables
        self.router = ExpertRouter(client)
    
    def create_expert(
        self,
        expert_class: type,
        expert_type: str,
        x1: str,
        x2: str,
        **kwargs
    ) -> BaseExpert:
        """Create an expert instance."""
        base_prompt = ""  # Will be generated by the expert
        expert = expert_class(
            base_prompt=base_prompt,
            x1=x1,
            x2=x2,
            client=self.client,
            all_variables=', '.join(self.all_variables),
            expert_type=expert_type,
            **kwargs
        )
        # Generate the actual prompt
        expert.base_prompt = expert.generate_question()
        return expert
    
    def run_with_experts(
        self,
        expert_class: type,
        question_type: str,
        x1: str,
        x2: str,
        **expert_kwargs
    ) -> Dict[str, Any]:
        """
        Run a task using multiple experts.
        
        Args:
            expert_class: The expert class to instantiate
            question_type: Type of question for routing
            x1: First variable
            x2: Second variable
            **expert_kwargs: Additional arguments for expert creation
            
        Returns:
            Aggregated judgment result
        """
        # Select experts
        selected_expert_types = self.router.select_experts(question_type, x1, x2)
        print(f"Selected experts for '{question_type}': {selected_expert_types}")
        
        # Execute expert judgments
        expert_results = []
        for expert_type in selected_expert_types:
            try:
                expert = self.create_expert(
                    expert_class,
                    expert_type,
                    x1,
                    x2,
                    **expert_kwargs
                )
                result = expert.judge()
                expert_results.append(result)
                print(f"Expert {expert_type} completed: label={result['label']}")
            except Exception as e:
                print(f"Expert {expert_type} failed: {e}")
                continue
        
        # Aggregate results
        if not expert_results:
            print("All experts failed, using default method")
            # Fallback to single expert
            default_expert = self.create_expert(
                expert_class,
                "statistical",
                x1,
                x2,
                **expert_kwargs
            )
            return default_expert.judge()
        
        final_result = aggregate_expert_results(expert_results)
        print(f"Aggregated result: label={final_result['label']}")
        
        return final_result


class TreeQueryTask(CausalInferenceTask):
    """
    Tree-based causal query task that systematically analyzes causal relationships.
    
    This task follows a decision tree logic to determine causal relationships:
    1. Check for backdoor paths
    2. If backdoor exists, analyze after blocking
    3. Check independence, latent confounders, and causal direction
    """
    
    def query(self, x1: str, x2: str) -> Dict[str, Any]:
        """
        Execute tree query to determine causal relationship.
        
        Args:
            x1: First variable (potential cause)
            x2: Second variable (potential effect)
            
        Returns:
            Dictionary with:
                - relation: 'x->y', 'y->x', 'x<->y', or 'independent'
                - log: Execution log with intermediate results
        """
        log = []
        
        # Step 1: Check for backdoor path
        print("=== Step 1: Check Backdoor Path ===")
        res_backdoor = self.run_with_experts(
            BackdoorPathExpert,
            "backdoor_path",
            x1,
            x2
        )
        log.append(("backdoor_path", res_backdoor))
        
        if res_backdoor["label"] == 1:
            print("Backdoor path exists, analyzing after blocking")
            
            # Step 2: Check independence after blocking
            print("=== Step 2: Check Independence After Blocking ===")
            res_ind = self.run_with_experts(
                IndependenceExpert,
                "independence",
                x1,
                x2,
                after_blocking=True
            )
            log.append(("independent_after_block", res_ind))
            
            if res_ind["label"] == 1:
                return {
                    "relation": "independent",
                    "log": log
                }
            
            # Step 3: Check for latent confounder
            print("=== Step 3: Check Latent Confounder ===")
            res_latent = self.run_with_experts(
                LatentConfounderExpert,
                "latent_confounder",
                x1,
                x2,
                after_blocking=True
            )
            log.append(("latent_confounder_after_block", res_latent))
            
            if res_latent["label"] == 1:
                return {
                    "relation": "x<->y",
                    "log": log
                }
            
            # Step 4: Determine causal direction
            print("=== Step 4: Determine Causal Direction ===")
            res_dir = self.run_with_experts(
                CausalDirectionExpert,
                "causal_direction",
                x1,
                x2,
                after_blocking=True
            )
            log.append(("x->y_after_block", res_dir))
            
            if res_dir["label"] == 1:
                return {
                    "relation": "x->y",
                    "log": log
                }
            else:
                return {
                    "relation": "y->x",
                    "log": log
                }
        
        else:
            print("No backdoor path, direct analysis")
            
            # Check independence without blocking
            res_ind = self.run_with_experts(
                IndependenceExpert,
                "independence",
                x1,
                x2,
                after_blocking=False
            )
            log.append(("independent_no_backdoor", res_ind))
            
            if res_ind["label"] == 1:
                return {
                    "relation": "independent",
                    "log": log
                }
            
            # Check for latent confounder
            res_latent = self.run_with_experts(
                LatentConfounderExpert,
                "latent_confounder",
                x1,
                x2,
                after_blocking=False
            )
            log.append(("latent_confounder_no_backdoor", res_latent))
            
            if res_latent["label"] == 1:
                return {
                    "relation": "x<->y",
                    "log": log
                }
            
            # Determine causal direction
            res_dir = self.run_with_experts(
                CausalDirectionExpert,
                "causal_direction",
                x1,
                x2,
                after_blocking=False
            )
            log.append(("x->y_no_backdoor", res_dir))
            
            if res_dir["label"] == 1:
                return {
                    "relation": "x->y",
                    "log": log
                }
            else:
                return {
                    "relation": "y->x",
                    "log": log
                }


class PairwiseCausalAnalysisTask(CausalInferenceTask):
    """
    Analyze causal relationships for all variable pairs in a system.
    """
    
    def analyze_all_pairs(self) -> Dict[Tuple[str, str], Dict[str, Any]]:
        """
        Compute causal relationships for all pairs of variables.
        
        Returns:
            Dictionary mapping variable pairs to their causal relationships
        """
        all_relations = {}
        tree_query = TreeQueryTask(
            self.client,
            self.all_variables
        )
        
        for x1, x2 in combinations(self.all_variables, 2):
            print(f"\n{'='*60}")
            print(f"Analyzing relationship between {x1} and {x2}")
            print('='*60)
            
            result = tree_query.query(x1, x2)
            all_relations[(x1, x2)] = result
            
            print(f"\nResult: {result['relation']}")
        
        return all_relations
