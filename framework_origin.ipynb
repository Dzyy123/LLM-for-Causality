{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a383715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import math\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "client = openai.OpenAI(\n",
    "    api_key=\"\",  \n",
    "    base_url=\"https://llmapi.paratera.com/v1/\"  # 建议带上 https://\n",
    ")\n",
    "\n",
    "# === 工具函数 ===\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "def parse_probabilities(llm_output: str):\n",
    "    \"\"\"\n",
    "    从 LLM 文本输出中提取概率。\n",
    "    比如：\n",
    "    P(yes) = 0.0  \n",
    "    P(no) = 1.0\n",
    "    \"\"\"\n",
    "    matches = re.findall(r\"([0-9]*\\.?[0-9]+)\", llm_output)\n",
    "    if len(matches) >= 2:\n",
    "        p1, p2 = float(matches[0]), float(matches[1])\n",
    "        total = p1 + p2\n",
    "        if total == 0:\n",
    "            return 0.5, 0.5\n",
    "        return p1 / total, p2 / total\n",
    "    return 0.5, 0.5  # fallback\n",
    "\n",
    "def parse_logits(llm_output: str):\n",
    "    matches = re.findall(r\"([-]?[0-9]*\\.?[0-9]+)\", llm_output)\n",
    "    if len(matches) >= 2:\n",
    "        l1, l2 = float(matches[0]), float(matches[1])\n",
    "        if not math.isclose(l1 + l2, 0):\n",
    "            avg = (l1 - l2) / 2\n",
    "            l1, l2 = avg, -avg\n",
    "        return l1, l2\n",
    "    return 0.0, 0.0\n",
    "\n",
    "def llm_judge_openai(prompt, x1, x2, method='probability', n_sample=10):\n",
    "    \"\"\"\n",
    "    使用 client.chat.completions.create\n",
    "    method: 'frequency' | 'probability' | 'logit'\n",
    "    返回: {\"label\": 1或0, \"prob\": 最大概率}\n",
    "    \"\"\"\n",
    "\n",
    "    if method == 'frequency':\n",
    "        votes = []\n",
    "        for _ in range(n_sample):\n",
    "            resp = client.chat.completions.create(\n",
    "                model=\"DeepSeek-R1-0528\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                max_tokens=50,\n",
    "                temperature=0.7,\n",
    "            )\n",
    "            text = resp.choices[0].message.content.strip()\n",
    "            votes.append(1 if text.lower().startswith(\"yes\") else 0)\n",
    "\n",
    "        p_yes = sum(votes) / len(votes)\n",
    "        p_no = 1 - p_yes\n",
    "        # 取最大标签与其概率（平局默认选 yes=>1）\n",
    "        if p_yes >= p_no:\n",
    "            return {\"label\": 1, \"prob\": p_yes}\n",
    "        else:\n",
    "            return {\"label\": 0, \"prob\": p_no}\n",
    "\n",
    "    elif method == 'probability':\n",
    "        resp = client.chat.completions.create(\n",
    "            model=\"DeepSeek-R1-0528\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=200,\n",
    "            temperature=0.7,\n",
    "        )\n",
    "        text = resp.choices[0].message.content.strip()\n",
    "        print(\"LLM 原始输出：\\n\", text)  # 调试用\n",
    "\n",
    "        p_yes, p_no = parse_probabilities(text)\n",
    "        if p_yes >= p_no:\n",
    "            return {\"label\": 1, \"prob\": p_yes}\n",
    "        else:\n",
    "            return {\"label\": 0, \"prob\": p_no}\n",
    "\n",
    "    elif method == 'logit':\n",
    "        resp = client.chat.completions.create(\n",
    "            model=\"DeepSeek-R1-0528\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=200,\n",
    "            temperature=0.7,\n",
    "        )\n",
    "        text = resp.choices[0].message.content.strip()\n",
    "        logit_yes, logit_no = parse_logits(text)\n",
    "        p_yes = sigmoid(logit_yes)\n",
    "        p_no = sigmoid(logit_no)\n",
    "\n",
    "        if p_yes >= p_no:\n",
    "            return {\"label\": 1, \"prob\": p_yes}\n",
    "        else:\n",
    "            return {\"label\": 0, \"prob\": p_no}\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Method should be one of 'frequency', 'probability', or 'logit'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "256cddd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_backdoor(x1, x2, method='logit'):\n",
    "    prompt = f\"请判断 {x1} 与 {x2} 之间是否存在 back-door path。\" \\\n",
    "             f\"请直接输出概率或 logit，并确保满足 Kolmogorov 公理（或 logit1 + logit2 = 0）。\"\n",
    "    return llm_judge_openai(prompt, x1, x2, method)\n",
    "\n",
    "def check_independence_after_block(x1, x2, method='logit'):\n",
    "    prompt = f\"阻断 back-door path 后，{x1} 与 {x2} 是否独立？\" \\\n",
    "             f\"请输出概率对或 logit，并确保满足 Kolmogorov 公理（或 logit1 + logit2 = 0）。\"\n",
    "    return llm_judge_openai(prompt, x1, x2, method)\n",
    "\n",
    "def check_latent_confounder_after_block(x1, x2, method='logit'):\n",
    "    prompt = f\"阻断 back-door path 后，{x1} 与 {x2} 是否存在潜在混杂因子？\" \\\n",
    "             f\"请输出概率对或 logit，并确保满足 Kolmogorov 公理（或 logit1 + logit2 = 0）。\"\n",
    "    return llm_judge_openai(prompt, x1, x2, method)\n",
    "\n",
    "def check_causal_direction_after_block(x1, x2, method='logit'):\n",
    "    prompt = f\"阻断 back-door path 后，请判断 {x1} 是否会导致 {x2}。\" \\\n",
    "             f\"请输出概率对或 logit，并确保满足 Kolmogorov 公理（或 logit1 + logit2 = 0）。\"\n",
    "    return llm_judge_openai(prompt, x1, x2, method)\n",
    "\n",
    "def check_independence(x1, x2, method='logit'):\n",
    "    prompt = f\"请判断 {x1} 与 {x2} 是否独立。\" \\\n",
    "             f\"请输出概率或 logit，并确保满足 Kolmogorov 公理（或 logit1 + logit2 = 0）。\"\n",
    "    return llm_judge_openai(prompt, x1, x2, method)\n",
    "\n",
    "def check_latent_confounder(x1, x2, method='logit'):\n",
    "    prompt = f\"请判断 {x1} 与 {x2} 之间是否存在潜在混杂因子。\" \\\n",
    "             f\"请输出概率或 logit，并确保满足 Kolmogorov 公理（或 logit1 + logit2 = 0）。\"\n",
    "    return llm_judge_openai(prompt, x1, x2, method)\n",
    "\n",
    "def check_causal_direction(x1, x2, method='logit'):\n",
    "    prompt = f\"请判断 {x1} 是否会导致 {x2}。\" \\\n",
    "             f\"请输出概率或 logit，并确保满足 Kolmogorov 公理（或 logit1 + logit2 = 0）。\"\n",
    "    return llm_judge_openai(prompt, x1, x2, method)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ec3d40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM 原始输出：\n",
      " 在标准因果推断框架下，针对变量 \"age\" 和 \"blood pressure\"，我们考虑一个常见的因果图模型。通常，\"age\" 被视为一个外生变量（没有指向它的箭头），而 \"blood pressure\" 是结果变量。如果因果图中仅包含从 \"age\" 到 \"blood pressure\" 的直接路径（即 age → blood pressure），并且没有其他变量（如混杂因素）连接两者，则不存在后门路径（back-door path）。后门路径要求路径中包含指向 \"age\" 的箭头，但作为外生变量，\"age\" 没有此类路径。\n",
      "\n",
      "基于医学和因果推断的常见知识，在缺乏额外变量（如遗传或生活方式因素）的简单模型中，\"age\" 和 \"blood pressure\" 之间通常不存在后门路径。因此，我们判断后门路径存在的概率较低。\n",
      "\n",
      "为满足问题要求，输出概率并确保 Kolmogorov 公理（概率非负且和为1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'label': 1, 'prob': 0.5}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_backdoor('age', 'blood presure', method='probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18f0599d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: LLM 生成因果知识\n",
    "def tree_query(x1, x2, method='probability'):\n",
    "    \"\"\"\n",
    "    基于树状逻辑的因果方向查询器（不做阈值判断）。\n",
    "    每一步子检查函数都返回: {\"label\": 1或0, \"prob\": float}\n",
    "\n",
    "    输出:\n",
    "        {\n",
    "            'relation': 'x->y' | 'y->x' | 'x<->y' | 'independent',\n",
    "            'confidence': float,   # 取决定该结论的那一步的 prob\n",
    "            'log': [(step_name, {'label': int, 'prob': float}), ...]\n",
    "        }\n",
    "    \"\"\"\n",
    "    log = []\n",
    "\n",
    "    # Step 1: 是否存在 backdoor path?\n",
    "    res_backdoor = check_backdoor(x1, x2, method)\n",
    "    log.append((\"backdoor_path\", res_backdoor))\n",
    "\n",
    "    if res_backdoor[\"label\"] == 1:\n",
    "        # Step 2: 阻断路径后是否独立？\n",
    "        res_ind = check_independence_after_block(x1, x2, method)\n",
    "        log.append((\"independent_after_block\", res_ind))\n",
    "        if res_ind[\"label\"] == 1:\n",
    "            return {\"relation\": \"independent\", \"confidence\": res_ind[\"prob\"], \"log\": log}\n",
    "\n",
    "        # Step 3: 是否存在潜在混杂因子？\n",
    "        res_latent = check_latent_confounder_after_block(x1, x2, method)\n",
    "        log.append((\"latent_confounder_after_block\", res_latent))\n",
    "        if res_latent[\"label\"] == 1:\n",
    "            return {\"relation\": \"x<->y\", \"confidence\": res_latent[\"prob\"], \"log\": log}\n",
    "\n",
    "        # Step 4: 判断方向 (x→y?)\n",
    "        res_dir = check_causal_direction_after_block(x1, x2, method)\n",
    "        log.append((\"x->y_after_block\", res_dir))\n",
    "        if res_dir[\"label\"] == 1:\n",
    "            return {\"relation\": \"x->y\", \"confidence\": res_dir[\"prob\"], \"log\": log}\n",
    "        else:\n",
    "            return {\"relation\": \"y->x\", \"confidence\": res_dir[\"prob\"], \"log\": log}\n",
    "\n",
    "    else:\n",
    "        # 不存在 backdoor path\n",
    "        res_ind = check_independence(x1, x2, method)\n",
    "        log.append((\"independent_no_backdoor\", res_ind))\n",
    "        if res_ind[\"label\"] == 1:\n",
    "            return {\"relation\": \"independent\", \"confidence\": res_ind[\"prob\"], \"log\": log}\n",
    "\n",
    "        res_latent = check_latent_confounder(x1, x2, method)\n",
    "        log.append((\"latent_confounder_no_backdoor\", res_latent))\n",
    "        if res_latent[\"label\"] == 1:\n",
    "            return {\"relation\": \"x<->y\", \"confidence\": res_latent[\"prob\"], \"log\": log}\n",
    "\n",
    "        res_dir = check_causal_direction(x1, x2, method)\n",
    "        log.append((\"x->y_no_backdoor\", res_dir))\n",
    "        if res_dir[\"label\"] == 1:\n",
    "            return {\"relation\": \"x->y\", \"confidence\": res_dir[\"prob\"], \"log\": log}\n",
    "        else:\n",
    "            return {\"relation\": \"y->x\", \"confidence\": res_dir[\"prob\"], \"log\": log}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59873785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM 原始输出：\n",
      " 1.0\n",
      "LLM 原始输出：\n",
      " 在因果推断中，溺水人数（Drowning）与冰淇淋销量（Ice Cream Sales）之间的关联通常由混杂因子（如温度，Temperature）引起，而非直接因果关系。当阻断 back-door path（即控制混杂因子温度）后，溺水人数与冰淇淋销量在给定温度的条件下应满足条件独立。这是因为在控制温度后，两者之间的伪相关被消除，仅剩下随机变异。\n",
      "\n",
      "### 是否独立？\n",
      "是的，阻断 back-door path（控制温度）后，溺水人数与冰淇淋销量条件独立。即：\n",
      "\\[\n",
      "P(\\text{Drowning} \\mid \\text{Ice Cream Sales}, \\text{Temperature}) = P(\\text{Drowning} \\mid \\text{Temperature})\n",
      "\\]\n",
      "或等价地，联合概率满足：\n",
      "\\[\n",
      "P(\\text{Drowning}, \\text{Ice Cream Sales} \\mid \\text{Temperature}) = P(\\text{Drowning} \\mid \\text{Temperature}) \\times P(\\text{Ice\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'relation': 'independent',\n",
       " 'confidence': 0.5,\n",
       " 'log': [('backdoor_path', {'label': 1, 'prob': 0.5}),\n",
       "  ('independent_after_block', {'label': 1, 'prob': 0.5})]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_query('溺水人数', '冰淇淋销量', method='probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc47fbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM 原始输出：\n",
      " 在因果推断中，back-door path 是指从原因变量到结果变量的一条路径，该路径以指向原因变量的箭头开头（例如，通过一个共同原因或混淆变量）。对于“闪电”（lightning）和“打雷”（thunder）之间的关系：\n",
      "\n",
      "- 闪电是打雷的直接原因（闪电产生声波，即打雷），因此在基本因果图中，路径为 Lightning → Thunder。\n",
      "- 如果考虑更完整的模型，雷暴云（积雨云）作为共同原因，因果图可能为 Storm Cloud → Lightning → Thunder（即雷暴云导致闪电，闪电导致打雷）。在这个图中，从 Lightning 到 Thunder 的路径只有一条：Lightning → Thunder（前门路径）。没有以指向 Lightning 的箭头开头的路径（即没有如 Lightning ← Storm Cloud → Thunder 的有效路径，因为路径中节点不能重复，且没有直接的 Storm Cloud → Thunder 路径）。\n",
      "\n",
      "因此，在 Lightning 和 Thunder\n",
      "LLM 原始输出：\n",
      " 在因果推断中，阻断后门路径（back-door path）的目的是消除混杂偏倚（confounding bias），从而允许估计变量间的因果效应，但并不意味着变量之间会变得独立。闪电（Lightning）和打雷（Thunder）之间存在直接的因果路径（闪电导致打雷），因此即使在阻断后门路径后（例如，通过条件化在混杂变量上），闪电和打雷也不会独立。它们仍然由于直接因果效应而相关。\n",
      "\n",
      "### 原因分析：\n",
      "- 典型的因果图中，闪电（L）和打雷（T）可能受一个混杂变量（如风暴，Storm，记为 S）影响。因果路径为：\n",
      "  - \\(S \\rightarrow L\\)\n",
      "  - \\(S \\rightarrow T\\)\n",
      "  - \\(L \\rightarrow T\\)\n",
      "- 后门路径为 \\(L \\leftarrow S \\rightarrow T\\)。阻断此路径（例如，通过条件化在 S 上）后，混杂效应\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'relation': 'independent',\n",
       " 'confidence': 0.5,\n",
       " 'log': [('backdoor_path', {'label': 1, 'prob': 0.5}),\n",
       "  ('independent_after_block', {'label': 1, 'prob': 0.5})]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_query('闪电', '打雷', method='probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0944f774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM 原始输出：\n",
      " 3\n",
      "LLM 原始输出：\n",
      " 阻断 back-door path 后，教育年限与收入水平不独立。原因在于，back-door path 的阻断消除了混杂变量的影响（如家庭背景或个人能力），从而允许教育年限对收入水平的因果效应显现。教育年限通常对收入水平有积极影响（例如，更高教育年限往往导致更高收入），因此两个变量在条件分布下相关，而非独立。\n",
      "\n",
      "由于问题要求输出概率对或 logit，并满足 Kolmogorov 公理（概率和为1）或 logit 和为零，我将基于标准因果推断模型提供一个简单示例。假设收入水平是二元的（0 = 低收入, 1 = 高收入），教育年限为连续变量，但在输出时需固定一个教育年限值以计算具体概率。这里，我假设教育年限 = 12 年（典型高中毕业年限），并基于常见实证研究（如 Mincer 方程）设定参数，确保输出符合要求。\n",
      "\n",
      "### 输出概率对\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'relation': 'independent',\n",
       " 'confidence': 1.0,\n",
       " 'log': [('backdoor_path', {'label': 1, 'prob': 0.5}),\n",
       "  ('independent_after_block', {'label': 1, 'prob': 1.0})]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_query('教育年限', '收入水平', method='probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a47f78f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM 原始输出：\n",
      " 1.386, -1.386\n",
      "LLM 原始输出：\n",
      " 在因果推断中，阻断 back-door path（后门路径）通常是通过条件在混杂变量（confounder）上来实现，以消除混杂偏差，从而准确估计氟化物（F）对蛀牙（C）的因果效应。在标准因果图（例如，氟化物 → 蛀牙，并有混杂变量 U，如社会经济状态（SES），其中 U → 氟化物 和 U → 蛀牙）中，阻断 back-door path（例如，通过条件在 U 上）后，氟化物与蛀牙之间仍存在直接因果路径（氟化物 → 蛀牙）。因此，氟化物与蛀牙在条件上（给定 U）并不独立，除非因果效应为零（即氟化物对蛀牙无影响）。在现实中，氟化物通常被认为能减少蛀牙风险，因此因果效应存在，独立性不成立。\n",
      "\n",
      "### 回答：\n",
      "- **是否独立？** 否，阻断 back-door path 后\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'relation': 'independent',\n",
       " 'confidence': 0.5,\n",
       " 'log': [('backdoor_path', {'label': 1, 'prob': 0.5}),\n",
       "  ('independent_after_block', {'label': 1, 'prob': 0.5})]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_query('氟化物','蛀牙', method='probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03734d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: 多校准 (multi-Calibration)\n",
    "\n",
    "# 获取语义向量\n",
    "def get_llm_embeddings(vars_list, model=\"DeepSeek-R1-0528\"):\n",
    "    embeddings = []\n",
    "    for var in vars_list:\n",
    "        prompt = f\"\"\"请为变量「{var}」生成用于因果关系聚类的语义嵌入向量。\n",
    "要求：\n",
    "1. 向量维度为128维；\n",
    "2. 每个元素为-1到1之间的浮点数，保留4位小数；\n",
    "3. 用英文逗号分隔所有元素，仅输出向量本身；\n",
    "4. 向量需反映变量语义（如\"温度\"与\"冰淇淋销量\"向量相关）。\n",
    "示例输出：0.1234,0.5678,-0.9012,...,0.3456\"\"\"\n",
    "\n",
    "        \n",
    "        resp = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                max_tokens=1000,\n",
    "                temperature=0.3,\n",
    "            )\n",
    "\n",
    "        if not resp.choices or not resp.choices[0].message or resp.choices[0].message.content is None:\n",
    "                raise ValueError(\"LLM未返回有效内容（content为None）\")\n",
    "\n",
    "        text = resp.choices[0].message.content.strip()\n",
    "        if not text:\n",
    "                raise ValueError(\"LLM返回内容为空字符串\")\n",
    "\n",
    "            # 解析向量\n",
    "        vec = np.array([float(num.strip()) for num in text.split(',')])\n",
    "            # 确保维度为128\n",
    "        vec = np.pad(vec, (0, 128 - len(vec)), 'constant') if len(vec) < 128 else vec[:128]\n",
    "            # 归一化\n",
    "        vec = vec / np.max(np.abs(vec)) if np.max(np.abs(vec)) != 0 else vec\n",
    "        embeddings.append(vec)\n",
    "        print(f\"成功生成变量「{var}」的语义向量（128维）\")\n",
    "\n",
    "    return {var: emb for var, emb in zip(vars_list, embeddings)}\n",
    "\n",
    "#  用KMeans进行聚类\n",
    "def clustering(causal_knowledge, var_embeddings, n_clusters=2):\n",
    "    pair_list = list(causal_knowledge.keys())\n",
    "    pair_features = []\n",
    "    for pair in pair_list:\n",
    "        x1, x2 = pair\n",
    "        if x1 not in var_embeddings or x2 not in var_embeddings:\n",
    "            raise ValueError(f\"变量{x1}/{x2}无语义向量，请先调用get_llm_embeddings\")\n",
    "        feat = (var_embeddings[x1] + var_embeddings[x2]) / 2\n",
    "        pair_features.append(feat)\n",
    "    pair_features = np.array(pair_features)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(pair_features)\n",
    "\n",
    "    cluster_to_pairs = {}\n",
    "    for pair, label in zip(pair_list, cluster_labels):\n",
    "        cluster_id = f\"S_{label+1}\"\n",
    "        if cluster_id not in cluster_to_pairs:\n",
    "            cluster_to_pairs[cluster_id] = []\n",
    "        cluster_to_pairs[cluster_id].append(pair)\n",
    "\n",
    "    print(f\"\\n=== 硬聚类结果（{n_clusters}个集合S） ===\")\n",
    "    for cluster_id, pairs in cluster_to_pairs.items():\n",
    "        print(f\"集合{cluster_id}（{len(pairs)}个变量对）：{pairs}\")\n",
    "    return cluster_to_pairs, {pair: f\"S_{label+1}\" for pair, label in zip(pair_list, cluster_labels)}\n",
    "\n",
    "class ClusterInfo:\n",
    "    \"\"\"封装聚类相关信息，用于alpha_calibrate函数调用\"\"\"\n",
    "    def __init__(self, cluster_to_pairs, pair_to_cluster, var_embeddings, N, alpha, perturbation_strength):\n",
    "        self.cluster_to_pairs = cluster_to_pairs  # {簇ID: [变量对列表]}\n",
    "        self.pair_to_cluster = pair_to_cluster  # {变量对: 簇ID}\n",
    "        self.var_embeddings = var_embeddings    # 变量语义向量（用于聚类验证）\n",
    "        self.N = N                              # 总变量对数量（universe大小）\n",
    "        self.alpha = alpha                      # 算法3.1的α参数\n",
    "        self.perturbation_strength = perturbation_strength  # 首次迭代扰动强度，仅用于此代码运行\n",
    "\n",
    "#这里应该是调用统计查询获得真实基准p*(S)的函数，这里仅供代码运行\n",
    "def statistical_query_oracle(\n",
    "    S_pairs: list,\n",
    "    prob_type: str,\n",
    "    causal_knowledge: dict,\n",
    "    tau: float,\n",
    "    N: int,\n",
    "    iteration: int,\n",
    "    perturbation_strength: float = 0.03\n",
    ") -> float:\n",
    "    \"\"\"算法3.1的统计查询接口：返回真实基准p*_S的近似值（含首次扰动）\"\"\"\n",
    "    # 基础值：原始概率的簇内均值\n",
    "    base_p_star_S = np.mean([causal_knowledge[pair][prob_type] for pair in S_pairs])\n",
    "    S_size = len(S_pairs)\n",
    "\n",
    "    # 首次迭代添加语义合理的扰动\n",
    "    if iteration == 1:\n",
    "        if prob_type == \"causal\":\n",
    "            perturbation = perturbation_strength if base_p_star_S > 0.5 else -perturbation_strength\n",
    "        elif prob_type == \"independent\":\n",
    "            perturbation = perturbation_strength if base_p_star_S > 0.5 else -perturbation_strength\n",
    "        else:\n",
    "            perturbation = np.random.choice([-perturbation_strength, perturbation_strength])\n",
    "        perturbed_p_star_S = np.clip(base_p_star_S + perturbation, 0.01, 0.99)\n",
    "        p_star_S = perturbed_p_star_S\n",
    "    else:\n",
    "        p_star_S = base_p_star_S\n",
    "\n",
    "    # 误差控制（符合算法3.1的统计查询容忍度）\n",
    "    max_error = tau * N / S_size\n",
    "    error = np.random.uniform(-max_error, max_error)\n",
    "    p_star_S_with_error = np.clip(p_star_S + error, 0.01, 0.99)\n",
    "\n",
    "    return p_star_S_with_error\n",
    "\n",
    "\n",
    "def multi_calibration(\n",
    "    causal_knowledge: dict,\n",
    "    n_clusters: int = 2,\n",
    "    alpha: float = 0.05,\n",
    "    max_iter: int = 1000,\n",
    "    perturbation_strength: float = 0.03\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    使用校准函数调整推导的因果概率，确保与真实的因果关系匹配\n",
    "    校准过程：\n",
    "    - 使用嵌入的语义向量对因果知识进行硬聚类；\n",
    "    - 迭代调用alpha_calibrate，对每种概率类型分簇校准；\n",
    "    - 归一化概率，确保三种概率之和为1。\n",
    "    \n",
    "    输入：\n",
    "    - causal_knowledge: LLM生成的因果知识字典，格式：\n",
    "      {\n",
    "          ('X1', 'X2'): {\n",
    "              'independent': p_independent,\n",
    "              'latent': p_latent,\n",
    "              'causal': p_causal\n",
    "          },\n",
    "          ...\n",
    "      }\n",
    "    - n_clusters: 硬聚类的簇数（默认2）\n",
    "    - alpha: 校准精度参数（默认0.05）\n",
    "    - max_iter: 最大迭代次数（默认1000）\n",
    "    - perturbation_strength: 首次迭代的扰动强度（默认0.03）\n",
    "    \n",
    "    输出：\n",
    "    - calibrated_probabilities: 校准后的因果概率字典（格式与输入一致）\n",
    "    \"\"\"\n",
    "    # 生成所有变量的语义向量（聚类依赖）\n",
    "    print(\"=== 生成变量语义向量 ===\")\n",
    "    all_vars = list(set([var for pair in causal_knowledge.keys() for var in pair]))\n",
    "    var_embeddings = get_llm_embeddings(all_vars)\n",
    "\n",
    "    # 对变量对进行硬聚类（划分簇S）\n",
    "    print(\"\\n=== 步骤2：对变量对进行硬聚类 ===\")\n",
    "    cluster_to_pairs, pair_to_cluster = clustering(\n",
    "        causal_knowledge=causal_knowledge,\n",
    "        var_embeddings=var_embeddings,\n",
    "        n_clusters=n_clusters\n",
    "    )\n",
    "\n",
    "    # 初始化参数与ClusterInfo对象（封装聚类信息）\n",
    "    N = len(causal_knowledge)  # 总变量对数量\n",
    "    cluster_info = ClusterInfo(\n",
    "        cluster_to_pairs=cluster_to_pairs,\n",
    "        pair_to_cluster=pair_to_cluster,\n",
    "        var_embeddings=var_embeddings,\n",
    "        N=N,\n",
    "        alpha=alpha,\n",
    "        perturbation_strength=perturbation_strength\n",
    "    )\n",
    "    calibrated_probabilities = {pair: prob.copy() for pair, prob in causal_knowledge.items()}\n",
    "    updated = True\n",
    "    iteration = 0\n",
    "\n",
    "    # 迭代调用alpha_calibrate进行多校准\n",
    "    print(\"\\n=== 步骤3：迭代执行α校准 ===\")\n",
    "    while updated and iteration < max_iter:\n",
    "        updated = False\n",
    "        iteration += 1\n",
    "        print(f\"\\n=== 迭代{iteration}/{max_iter} ===\")\n",
    "\n",
    "        # 遍历所有变量对，对每种概率类型调用alpha_calibrate\n",
    "        temp_calibrated = calibrated_probabilities.copy()  # 临时存储本轮更新结果（避免迭代中相互影响）\n",
    "        for pair, probabilities in calibrated_probabilities.items():\n",
    "            # 对三种概率类型分别校准\n",
    "            for prob_type in ['independent', 'latent', 'causal']:\n",
    "                original_prob = probabilities[prob_type]\n",
    "                # 调用alpha_calibrate进行校准\n",
    "                calibrated_prob = alpha_calibrate(\n",
    "                    probability=original_prob,\n",
    "                    pair=pair,\n",
    "                    prob_type=prob_type,\n",
    "                    causal_knowledge=causal_knowledge,\n",
    "                    cluster_info=cluster_info,\n",
    "                    iteration=iteration,\n",
    "                    calibrated_probs=calibrated_probabilities  # 传入当前所有校准概率，用于计算x_S\n",
    "                )\n",
    "                # 暂存校准结果（本轮内不覆盖，避免影响其他变量对的x_S计算）\n",
    "                temp_calibrated[pair][prob_type] = calibrated_prob\n",
    "                # 若有更新，标记本轮为更新状态\n",
    "                if abs(calibrated_prob - original_prob) > 1e-6:  # 忽略微小浮点误差\n",
    "                    updated = True\n",
    "\n",
    "        # 更新校准概率，并对每个变量对的概率归一化（确保和为1）\n",
    "        for pair in temp_calibrated:\n",
    "            total = sum(temp_calibrated[pair].values())\n",
    "            if total > 0:\n",
    "                temp_calibrated[pair] = {\n",
    "                    k: round(v / total, 3)\n",
    "                    for k, v in temp_calibrated[pair].items()\n",
    "                }\n",
    "        calibrated_probabilities = temp_calibrated\n",
    "\n",
    "    # 输出迭代终止信息\n",
    "    print(f\"\\n=== 迭代终止 ===\")\n",
    "    print(f\"总迭代次数：{iteration}次（{'已收敛' if not updated else '达到最大迭代次数'}）\")\n",
    "    return calibrated_probabilities\n",
    "\n",
    "# 校准函数，模拟alpha校准效果\n",
    "def alpha_calibrate(\n",
    "    probability: float,\n",
    "    pair: tuple,\n",
    "    prob_type: str,\n",
    "    causal_knowledge: dict,\n",
    "    cluster_info: ClusterInfo,\n",
    "    iteration: int,\n",
    "    calibrated_probs: dict\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    算法3.1的α校准核心逻辑：\n",
    "    1. 根据变量对所属簇，获取簇内信息；\n",
    "    2. 调用统计查询获取真实基准p*_S；\n",
    "    3. 计算当前簇内预测均值x_S，判断偏差是否超阈值；\n",
    "    4. 超阈值则更新概率，返回校准后的值。\n",
    "    \"\"\"\n",
    "    # 获取当前变量对的簇信息\n",
    "    cluster_id = cluster_info.pair_to_cluster[pair]\n",
    "    S_pairs = cluster_info.cluster_to_pairs[cluster_id]  # 簇内所有变量对\n",
    "    S_size = len(S_pairs)\n",
    "    N = cluster_info.N\n",
    "    alpha = cluster_info.alpha\n",
    "    perturbation_strength = cluster_info.perturbation_strength\n",
    "\n",
    "    # 计算算法3.1的关键参数\n",
    "    gamma = S_size / N\n",
    "    tau = alpha * gamma / 4  # 统计查询容忍度\n",
    "    threshold = alpha * S_size - tau * N  # 偏差阈值\n",
    "\n",
    "    # 调用统计查询获取真实基准p*_S\n",
    "    p_star_S = statistical_query_oracle(\n",
    "        S_pairs=S_pairs,\n",
    "        prob_type=prob_type,\n",
    "        causal_knowledge=causal_knowledge,\n",
    "        tau=tau,\n",
    "        N=N,\n",
    "        iteration=iteration,\n",
    "        perturbation_strength=perturbation_strength\n",
    "    )\n",
    "\n",
    "    # 计算当前簇内预测均值x_S（基于所有变量对的当前校准概率）\n",
    "    x_S = np.mean([calibrated_probs[pair_in_S][prob_type] for pair_in_S in S_pairs])\n",
    "\n",
    "    # 计算偏差并判断是否更新\n",
    "    delta_S = p_star_S - x_S\n",
    "    print(f\"簇{cluster_id}（{prob_type}）：变量对{pair} → x_S={x_S:.3f}，ΔS={delta_S:.3f}，阈值={threshold:.3f}\")\n",
    "\n",
    "    if abs(delta_S) > threshold:\n",
    "        # 偏差超阈值，计算更新步长（均匀分配到簇内所有变量对）\n",
    "        update_step = delta_S / S_size\n",
    "        calibrated_prob = probability + update_step\n",
    "        print(f\"簇{cluster_id}（{prob_type}）：变量对{pair} → 原始={probability:.3f}，更新={update_step:.4f}\")\n",
    "    else:\n",
    "        # 偏差未超阈值，不更新\n",
    "        calibrated_prob = probability\n",
    "        print(f\"簇{cluster_id}（{prob_type}）：变量对{pair} → 偏差未超阈值，不更新\")\n",
    "\n",
    "    # 确保概率在[0.01, 0.99]范围内（避免极端值）\n",
    "    calibrated_prob = max(0.01, min(calibrated_prob, 0.99))\n",
    "    return calibrated_prob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e2c25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: 形成先验因果图\n",
    "def create_prior_causal_graph(calibrated_probabilities):\n",
    "    \"\"\"\n",
    "    根据校准后的因果概率生成先验因果图\n",
    "    - 使用三个概率判断每对变量之间的因果关系（独立性、潜在混杂变量、因果方向）。\n",
    "    - 根据综合判断结果生成因果图，可能会有双向箭头（<->）表示不确定或相互作用。\n",
    "    \n",
    "    输入：\n",
    "    - calibrated_probabilities: 每对变量的校准后概率字典，\n",
    "        格式：{\n",
    "            ('X1', 'X2'): {\n",
    "                'independent': p_independent,\n",
    "                'latent': p_latent,\n",
    "                'causal': p_causal\n",
    "            },\n",
    "            ...\n",
    "        }\n",
    "    输出：\n",
    "    - prior_graph: 先验因果图，格式为字典，键是变量对，值是因果关系（X->Y, Y->X, <->, independent）\n",
    "    \"\"\"\n",
    "    prior_graph = {}\n",
    "    \n",
    "    # 遍历每对变量，判断因果关系\n",
    "    for pair, probabilities in calibrated_probabilities.items():\n",
    "        p_independent = probabilities['independent']  # 独立性概率\n",
    "        p_latent = probabilities['latent']  # 潜在混杂变量概率\n",
    "        p_causal = probabilities['causal']  # 因果方向概率\n",
    "        \n",
    "        # 判断因果关系\n",
    "        if p_independent > 0.5:\n",
    "            # 如果独立性概率大于0.5，认为X1和X2是独立的\n",
    "            prior_graph[pair] = \"independent\"\n",
    "        elif p_latent > 0.5:\n",
    "            # 如果潜在混杂变量概率大于0.5，认为存在潜在混杂变量\n",
    "            prior_graph[pair] = \"<->\"  # 双向箭头表示不确定或相互作用\n",
    "        else:\n",
    "            # 根据因果关系概率判断因果方向\n",
    "            if p_causal > 0.5:\n",
    "                # 如果因果概率大于0.5，认为X1导致X2\n",
    "                prior_graph[pair] = f\"{pair[0]}->{pair[1]}\"\n",
    "            elif p_causal < 0.5:\n",
    "                # 如果因果概率小于0.5，认为X2导致X1\n",
    "                prior_graph[pair] = f\"{pair[1]}->{pair[0]}\"\n",
    "            else:\n",
    "                # 如果因果概率接近0.5，认为两者之间相互作用\n",
    "                prior_graph[pair] = \"<->\"\n",
    "    \n",
    "    return prior_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3566bb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: 使用BCCD结合数据生成后验因果图\n",
    "def generate_post_causal_graph(prior_graph, data):\n",
    "    \"\"\"\n",
    "    使用BCCD（贝叶斯因果链发现）结合数据生成后验因果图\n",
    "    - 结合先验因果图和实际数据，推导出后验因果关系。\n",
    "    - 应用约束（如无环性约束），确保生成的因果图合理。\n",
    "    \n",
    "    输入：先验因果图、数据\n",
    "    输出：后验因果图（推导出的因果关系图，满足约束条件）\n",
    "    \"\"\"\n",
    "    # 将先验因果图应用于数据，使用BCCD进一步推导因果关系\n",
    "    post_causal_graph = bccd_inference(data, prior_graph)\n",
    "    \n",
    "    # 对后验图进行约束，确保没有环路等不合理的因果关系\n",
    "    post_causal_graph = apply_constraints(post_causal_graph)\n",
    "    \n",
    "    return post_causal_graph\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
