{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b68620c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12-09 17:11:12 [INFO] llm_utils.online_client - Online LLM client initialized: Qwen3-Next-80B-A3B-Thinking\n",
      "开始因果推断分析...\n",
      "============================================================\n",
      "=== Step 1: 检查后门路径 ===\n",
      "12-09 17:11:13 [INFO] llm_utils.online_client - Online LLM client initialized: Qwen3-Next-80B-A3B-Thinking\n",
      "门诊agent原始响应: graph_theory,domain_knowledge,statistical\n",
      "门诊agent推荐: ['graph_theory', 'domain_knowledge', 'statistical']\n",
      "为问题 'backdoor_path' 选择的专家: ['graph_theory', 'domain_knowledge', 'statistical']\n",
      "专家 graph_theory 判断完成: label=1, prob=1.0\n",
      "专家 domain_knowledge 判断完成: label=1, prob=1.0\n",
      "专家 statistical 判断完成: label=1, prob=1.0\n",
      "专家整合结果: label=1, prob=1.0\n",
      "存在后门路径，进入阻断后分析路径\n",
      "=== Step 2: 检查阻断后独立性 ===\n",
      "12-09 17:12:25 [INFO] llm_utils.online_client - Online LLM client initialized: Qwen3-Next-80B-A3B-Thinking\n",
      "门诊agent原始响应: statistical, graph_theory, domain_knowledge\n",
      "门诊agent推荐: ['statistical', 'graph_theory', 'domain_knowledge']\n",
      "为问题 'independence' 选择的专家: ['statistical', 'graph_theory', 'domain_knowledge']\n",
      "专家 statistical 判断完成: label=1, prob=1.0\n",
      "专家 graph_theory 判断完成: label=1, prob=1.0\n",
      "专家 domain_knowledge 判断完成: label=1, prob=1.0\n",
      "专家整合结果: label=1, prob=1.0\n",
      "\n",
      "=== 最终结果 ===\n",
      "变量关系: independent\n",
      "总体置信度: 1.0000\n",
      "\n",
      "=== 详细执行日志 ===\n",
      "\n",
      "backdoor_path:\n",
      "  判断: 是\n",
      "  置信度: 1.0000\n",
      "  专家详情:\n",
      "    - graph_theory: Yes (prob=1.0000)\n",
      "    - domain_knowledge: Yes (prob=1.0000)\n",
      "    - statistical: Yes (prob=1.0000)\n",
      "\n",
      "independent_after_block:\n",
      "  判断: 是\n",
      "  置信度: 1.0000\n",
      "  专家详情:\n",
      "    - statistical: Yes (prob=1.0000)\n",
      "    - graph_theory: Yes (prob=1.0000)\n",
      "    - domain_knowledge: Yes (prob=1.0000)\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import re\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from llm_utils import OnlineLLMClient, setup_logging\n",
    "\n",
    "# ============== 配置 ==============\n",
    "setup_logging(level=\"INFO\")\n",
    "\n",
    "# 创建全局LLM客户端\n",
    "client = OnlineLLMClient(\n",
    "    api_key=\"sk-fnUHDzxXAimEnYgyX20Jag\",\n",
    "    base_url=\"https://llmapi.paratera.com/v1/\",\n",
    "    model_name=\"Qwen3-Next-80B-A3B-Thinking\",\n",
    "    max_tokens=200,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# === 工具函数 ===\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "def parse_probabilities(llm_output: str):\n",
    "    \"\"\"从LLM输出中提取概率\"\"\"\n",
    "    matches = re.findall(r\"([0-9]*\\.?[0-9]+)\", llm_output)\n",
    "    if len(matches) >= 2:\n",
    "        p1, p2 = float(matches[0]), float(matches[1])\n",
    "        total = p1 + p2\n",
    "        if total == 0:\n",
    "            return 0.5, 0.5\n",
    "        return p1 / total, p2 / total\n",
    "    return 0.5, 0.5\n",
    "\n",
    "def parse_logits(llm_output: str):\n",
    "    \"\"\"从LLM输出中提取logits\"\"\"\n",
    "    matches = re.findall(r\"([-]?[0-9]*\\.?[0-9]+)\", llm_output)\n",
    "    if len(matches) >= 2:\n",
    "        l1, l2 = float(matches[0]), float(matches[1])\n",
    "        if not math.isclose(l1 + l2, 0):\n",
    "            avg = (l1 - l2) / 2\n",
    "            l1, l2 = avg, -avg\n",
    "        return l1, l2\n",
    "    return 0.0, 0.0\n",
    "\n",
    "def llm_judge_with_utils(prompt, x1, x2, method='frequency', n_sample=10):\n",
    "    \"\"\"\n",
    "    使用llm_utils进行判断\n",
    "    \"\"\"\n",
    "    if method == 'frequency':\n",
    "        votes = []\n",
    "        for _ in range(n_sample):\n",
    "            response = client.chat(prompt)\n",
    "            text = response.content.strip()\n",
    "            votes.append(1 if text.lower().startswith(\"yes\") else 0)\n",
    "        \n",
    "        p_yes = sum(votes) / len(votes)\n",
    "        p_no = 1 - p_yes\n",
    "        \n",
    "        if p_yes >= p_no:\n",
    "            return {\"label\": 1, \"prob\": p_yes}\n",
    "        else:\n",
    "            return {\"label\": 0, \"prob\": p_no}\n",
    "    \n",
    "    elif method == 'probability':\n",
    "        response = client.chat(prompt)\n",
    "        text = response.content.strip()\n",
    "        p_yes, p_no = parse_probabilities(text)\n",
    "        \n",
    "        if p_yes >= p_no:\n",
    "            return {\"label\": 1, \"prob\": p_yes}\n",
    "        else:\n",
    "            return {\"label\": 0, \"prob\": p_no}\n",
    "    \n",
    "    elif method == 'logit':\n",
    "        response = client.chat(prompt)\n",
    "        text = response.content.strip()\n",
    "        logit_yes, logit_no = parse_logits(text)\n",
    "        p_yes = sigmoid(logit_yes)\n",
    "        p_no = sigmoid(logit_no)\n",
    "        \n",
    "        if p_yes >= p_no:\n",
    "            return {\"label\": 1, \"prob\": p_yes}\n",
    "        else:\n",
    "            return {\"label\": 0, \"prob\": p_no}\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Method should be one of 'frequency', 'probability', or 'logit'\")\n",
    "\n",
    "# === MoE 专家定义 ===\n",
    "CAUSAL_EXPERTS = {\n",
    "    \"graph_theory\": {\n",
    "        \"name\": \"因果图论专家\",\n",
    "        \"description\": \"专门分析因果图结构，精通d-分离、路径阻断、后门准则等图论概念。推理方式：系统检查所有可能的路径，分析路径上的变量类型和连接方式，使用严谨的图论推理链条。\",\n",
    "        \"specialty\": \"路径分析、环路检测、d-分离判断\",\n",
    "        \"reasoning_style\": \"结构化图遍历\",\n",
    "        \"output_format\": \"基于图结构的二值判断\"\n",
    "    },\n",
    "    \"statistical\": {\n",
    "        \"name\": \"计量统计专家\", \n",
    "        \"description\": \"专注于统计检验和概率独立性分析，擅长相关性分析、条件独立性检验、混淆变量检测。推理方式：考虑样本分布、统计显著性、置信区间等统计概念。\",\n",
    "        \"specialty\": \"独立性检验、相关性分析、混淆检测\",\n",
    "        \"reasoning_style\": \"概率统计推理\",\n",
    "        \"output_format\": \"基于统计证据的概率判断\"\n",
    "    },\n",
    "    \"domain_knowledge\": {\n",
    "        \"name\": \"领域先验专家\",\n",
    "        \"description\": \"基于现实世界知识和科学常识进行因果推理，考虑时间顺序、物理可能性、生物学机制等约束。推理方式：结合文献证据、科学理论和常识性约束。\",\n",
    "        \"specialty\": \"机制分析、时序推理、现实约束\",\n",
    "        \"reasoning_style\": \"基于证据的归纳推理\", \n",
    "        \"output_format\": \"基于领域知识的合理性判断\"\n",
    "    },\n",
    "    \"counterfactual\": {\n",
    "        \"name\": \"反事实干预专家\",\n",
    "        \"description\": \"从干预和潜在结果角度分析因果关系，考虑do-calculus、随机化实验理想情况。推理方式：构建反事实场景，分析干预后的可能变化。\",\n",
    "        \"specialty\": \"干预分析、潜在结果、do算子\",\n",
    "        \"reasoning_style\": \"反事实思维实验\",\n",
    "        \"output_format\": \"基于干预推理的因果判断\"\n",
    "    },\n",
    "    \"temporal_dynamics\": {\n",
    "        \"name\": \"时间动态专家\",\n",
    "        \"description\": \"专门分析时间顺序和动态过程，强调原因必须发生在结果之前，考虑延迟效应和动态反馈。推理方式：严格检查时间顺序，分析因果链的时间特性。\",\n",
    "        \"specialty\": \"时序分析、动态过程、延迟效应\",\n",
    "        \"reasoning_style\": \"时间序列推理\", \n",
    "        \"output_format\": \"基于时间顺序的因果判断\"\n",
    "    },\n",
    "    \"mechanism_modeling\": {\n",
    "        \"name\": \"机制建模专家\", \n",
    "        \"description\": \"专注于因果机制的可解释性建模，分析中间变量、中介效应和机制路径。推理方式：构建机制框图，分析变量间的功能关系。\",\n",
    "        \"specialty\": \"中介分析、机制路径、功能关系\",\n",
    "        \"reasoning_style\": \"机制分解建模\",\n",
    "        \"output_format\": \"基于机制完整性的判断\"\n",
    "    },\n",
    "    \"robustness_analysis\": {\n",
    "        \"name\": \"稳健性检验专家\",\n",
    "        \"description\": \"专门评估因果关系的稳健性和敏感性，考虑不同假设下的结果稳定性。推理方式：进行敏感性分析，检验边界条件和假设变化的影响。\",\n",
    "        \"specialty\": \"敏感性分析、稳健检验、边界情况\",\n",
    "        \"reasoning_style\": \"多情景验证\",\n",
    "        \"output_format\": \"基于稳健性评估的判断\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# === Router 函数（增强版）===\n",
    "def expert_router(question_type: str, x1: str, x2: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    根据问题类型和变量特征选择最相关的专家\n",
    "    \"\"\"\n",
    "    # 基础路由规则\n",
    "    routing_rules = {\n",
    "        \"backdoor_path\": [\n",
    "            \"graph_theory\", \"statistical\", \"counterfactual\", \"temporal_dynamics\", \n",
    "            \"mechanism_modeling\", \"robustness_analysis\", \"domain_knowledge\"\n",
    "        ],\n",
    "        \"independence\": [\n",
    "            \"statistical\", \"graph_theory\", \"counterfactual\", \"robustness_analysis\",\n",
    "            \"temporal_dynamics\", \"mechanism_modeling\", \"domain_knowledge\"\n",
    "        ],\n",
    "        \"latent_confounder\": [\n",
    "            \"domain_knowledge\", \"statistical\", \"mechanism_modeling\", \"counterfactual\",\n",
    "            \"robustness_analysis\", \"graph_theory\", \"temporal_dynamics\"\n",
    "        ],\n",
    "        \"causal_direction\": [\n",
    "            \"temporal_dynamics\", \"domain_knowledge\", \"counterfactual\", \"mechanism_modeling\",\n",
    "            \"statistical\", \"graph_theory\", \"robustness_analysis\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # 获取基础专家列表\n",
    "    base_experts = routing_rules.get(question_type, list(CAUSAL_EXPERTS.keys()))\n",
    "    \n",
    "    # 使用门诊LLM agent来智能选择专家\n",
    "    try:\n",
    "        clinic_recommendation = clinic_agent_recommend(question_type, x1, x2, base_experts)\n",
    "        return clinic_recommendation\n",
    "    except Exception as e:\n",
    "        print(f\"门诊agent路由失败: {e}，使用基础路由\")\n",
    "        # 失败时返回基础专家列表的前3个\n",
    "        return base_experts[:3]\n",
    "\n",
    "def clinic_agent_recommend(question_type: str, x1: str, x2: str, base_experts: List[str]) -> List[str]:\n",
    "    \"\"\"\n",
    "    门诊LLM agent：根据具体变量和问题类型推荐最相关的专家\n",
    "    \"\"\"\n",
    "    # 使用独立的LLM客户端进行推荐\n",
    "    clinic_client = OnlineLLMClient(\n",
    "        api_key=\"sk-fnUHDzxXAimEnYgyX20Jag\",\n",
    "        base_url=\"https://llmapi.paratera.com/v1/\",\n",
    "        model_name=\"Qwen3-Next-80B-A3B-Thinking\",\n",
    "        max_tokens=200,\n",
    "        temperature=0.1\n",
    "    )\n",
    "    \n",
    "    # 构建专家选择提示\n",
    "    experts_description = \"\\n\".join([\n",
    "        f\"- {expert}: {CAUSAL_EXPERTS[expert]['description']}\" \n",
    "        for expert in base_experts\n",
    "    ])\n",
    "    \n",
    "    clinic_prompt = f\"\"\"\n",
    "作为因果推断门诊专家，你需要为以下因果分析任务选择最合适的专家组合：\n",
    "\n",
    "**分析任务**: {question_type}\n",
    "**变量对**: {x1} 和 {x2}\n",
    "\n",
    "**可用专家列表**:\n",
    "{experts_description}\n",
    "\n",
    "**选择要求**:\n",
    "1. 根据变量内容和问题类型，选择最相关的3个专家\n",
    "2. 按相关性从高到低排序\n",
    "3. 确保专家视角的多样性（不要选择推理方式相似的专家）\n",
    "4. 考虑变量的领域特性（医学、经济、社会等）\n",
    "\n",
    "请按照以下格式输出：\n",
    "最终推荐专家: 专家1, 专家2, 专家3\n",
    "\n",
    "**注意**: 只输出专家名称，用逗号分隔，不要添加其他文字。\n",
    "\"\"\"\n",
    "    \n",
    "    # 调用LLM获取推荐\n",
    "    response = clinic_client.chat(clinic_prompt)\n",
    "    response_text = response.content.strip()\n",
    "    print(f\"门诊agent原始响应: {response_text}\")\n",
    "    \n",
    "    # 解析返回的专家列表\n",
    "    recommended_experts = parse_clinic_recommendation(response_text, base_experts)\n",
    "    \n",
    "    print(f\"门诊agent推荐: {recommended_experts}\")\n",
    "    \n",
    "    return recommended_experts\n",
    "\n",
    "def parse_clinic_recommendation(response_text: str, base_experts: List[str]) -> List[str]:\n",
    "    \"\"\"\n",
    "    解析门诊agent的推荐结果\n",
    "    \"\"\"\n",
    "    # 方法1: 查找\"最终推荐专家\"后的内容\n",
    "    if \"最终推荐专家\" in response_text:\n",
    "        parts = response_text.split(\"最终推荐专家\")\n",
    "        if len(parts) > 1:\n",
    "            expert_line = parts[1].strip().lstrip(\":\").strip()\n",
    "            return extract_experts_from_line(expert_line, base_experts)\n",
    "    \n",
    "    # 方法2: 查找最后一行\n",
    "    lines = [line.strip() for line in response_text.split('\\n') if line.strip()]\n",
    "    if lines:\n",
    "        last_line = lines[-1]\n",
    "        experts = extract_experts_from_line(last_line, base_experts)\n",
    "        if len(experts) >= 2:\n",
    "            return experts\n",
    "    \n",
    "    # 方法3: 在整个文本中搜索专家名称\n",
    "    found_experts = []\n",
    "    for expert in base_experts:\n",
    "        if expert in response_text:\n",
    "            found_experts.append(expert)\n",
    "    \n",
    "    if len(found_experts) >= 2:\n",
    "        return found_experts[:3]  # 取前3个找到的专家\n",
    "    \n",
    "    # 如果所有方法都失败，返回基础专家前3个\n",
    "    print(f\"门诊agent解析不充分，使用基础专家: {base_experts[:3]}\")\n",
    "    return base_experts[:3]\n",
    "\n",
    "def extract_experts_from_line(line: str, base_experts: List[str]) -> List[str]:\n",
    "    \"\"\"从一行文本中提取专家名称\"\"\"\n",
    "    experts = []\n",
    "    \n",
    "    # 清理行内容\n",
    "    clean_line = line.replace('：', ':').replace('，', ',').replace(' ', '')\n",
    "    \n",
    "    # 多种分割方式尝试\n",
    "    separators = [',', '、', ';', '，']\n",
    "    \n",
    "    for sep in separators:\n",
    "        if sep in clean_line:\n",
    "            parts = [part.strip() for part in clean_line.split(sep)]\n",
    "            break\n",
    "    else:\n",
    "        parts = [clean_line]\n",
    "    \n",
    "    for part in parts:\n",
    "        clean_part = part.lower().replace('专家', '').replace('expert', '').strip()\n",
    "        \n",
    "        # 直接匹配专家名称\n",
    "        for expert in base_experts:\n",
    "            if (expert in clean_part or \n",
    "                expert.replace('_', ' ') in clean_part or\n",
    "                CAUSAL_EXPERTS[expert]['name'] in part):\n",
    "                if expert not in experts:\n",
    "                    experts.append(expert)\n",
    "                    break\n",
    "        \n",
    "        if len(experts) >= 3:\n",
    "            break\n",
    "    \n",
    "    return experts\n",
    "\n",
    "# === 专家提示创建函数 ===\n",
    "def create_expert_prompt(base_prompt: str, expert_type: str, x1: str, x2: str) -> str:\n",
    "    \"\"\"\n",
    "    为不同专家创建专业化的prompt\n",
    "    \"\"\"\n",
    "    expert_info = CAUSAL_EXPERTS[expert_type]\n",
    "    \n",
    "    expert_specific_prompts = {\n",
    "        \"graph_theory\": f\"\"\"作为{expert_info['name']}，请严格遵循以下专业分析框架：\n",
    "\n",
    "{expert_info['description']}\n",
    "\n",
    "专业特长：{expert_info['specialty']}\n",
    "推理风格：{expert_info['reasoning_style']}\n",
    "输出要求：基于图结构的二值判断\n",
    "\n",
    "分析步骤：\n",
    "1. 构建因果图模型，识别所有可能的路径\n",
    "2. 应用d-分离准则分析路径阻塞情况  \n",
    "3. 检查后门路径、前门路径和混杂路径\n",
    "4. 基于图结构做出明确的二值判断\n",
    "\n",
    "请严格按照图论原理进行分析，直接输出是或否（Yes/No）。\\n\\n{base_prompt}\"\"\",\n",
    "\n",
    "        \"statistical\": f\"\"\"作为{expert_info['name']}，请严格遵循以下专业分析框架：\n",
    "\n",
    "{expert_info['description']}\n",
    "\n",
    "专业特长：{expert_info['specialty']}\n",
    "推理风格：{expert_info['reasoning_style']}\n",
    "输出要求：基于统计证据的二值判断\n",
    "\n",
    "分析步骤：\n",
    "1. 评估变量间的统计相关性\n",
    "2. 考虑条件独立性和混淆因素\n",
    "3. 分析统计显著性和置信度\n",
    "4. 基于概率证据做出明确的二值判断\n",
    "\n",
    "请基于统计原理进行严谨分析，直接输出是或否（Yes/No）。\\n\\n{base_prompt}\"\"\",\n",
    "\n",
    "        \"domain_knowledge\": f\"\"\"作为{expert_info['name']}，请严格遵循以下专业分析框架：\n",
    "\n",
    "{expert_info['description']}\n",
    "\n",
    "专业特长：{expert_info['specialty']}\n",
    "推理风格：{expert_info['reasoning_style']}\n",
    "输出要求：基于领域知识的二值判断\n",
    "\n",
    "分析步骤：\n",
    "1. 调用相关领域的科学知识和常识\n",
    "2. 考虑物理/生物/社会机制的合理性\n",
    "3. 评估时间顺序和现实约束条件\n",
    "4. 基于先验知识做出明确的二值判断\n",
    "\n",
    "请结合现实世界知识进行推理，直接输出是或否（Yes/No）。\\n\\n{base_prompt}\"\"\",\n",
    "\n",
    "        \"counterfactual\": f\"\"\"作为{expert_info['name']}，请严格遵循以下专业分析框架：\n",
    "\n",
    "{expert_info['description']}\n",
    "\n",
    "专业特长：{expert_info['specialty']}\n",
    "推理风格：{expert_info['reasoning_style']}\n",
    "输出要求：基于干预推理的二值判断\n",
    "\n",
    "分析步骤：\n",
    "1. 构建干预场景（do-操作）\n",
    "2. 比较实际结果与反事实结果\n",
    "3. 分析潜在结果分布\n",
    "4. 基于干预效应做出明确的二值判断\n",
    "\n",
    "请使用反事实推理进行分析，直接输出是或否（Yes/No）。\\n\\n{base_prompt}\"\"\",\n",
    "\n",
    "        \"temporal_dynamics\": f\"\"\"作为{expert_info['name']}，请严格遵循以下专业分析框架：\n",
    "\n",
    "{expert_info['description']}\n",
    "\n",
    "专业特长：{expert_info['specialty']}\n",
    "推理风格：{expert_info['reasoning_style']}\n",
    "输出要求：基于时间顺序的二值判断\n",
    "\n",
    "分析步骤：\n",
    "1. 严格检查原因和结果的时间顺序\n",
    "2. 分析延迟效应和动态过程\n",
    "3. 考虑时间序列的因果结构\n",
    "4. 基于时间约束做出明确的二值判断\n",
    "\n",
    "请重点分析时间维度，直接输出是或否（Yes/No）。\\n\\n{base_prompt}\"\"\",\n",
    "\n",
    "        \"mechanism_modeling\": f\"\"\"作为{expert_info['name']}，请严格遵循以下专业分析框架：\n",
    "\n",
    "{expert_info['description']}\n",
    "\n",
    "专业特长：{expert_info['specialty']}\n",
    "推理风格：{expert_info['reasoning_style']}\n",
    "输出要求：基于机制完整性的二值判断\n",
    "\n",
    "分析步骤：\n",
    "1. 识别可能的中间机制和中介变量\n",
    "2. 分析因果链的功能完整性\n",
    "3. 评估机制路径的合理性\n",
    "4. 基于机制可解释性做出明确的二值判断\n",
    "\n",
    "请专注于机制分析，直接输出是或否（Yes/No）。\\n\\n{base_prompt}\"\"\",\n",
    "\n",
    "        \"robustness_analysis\": f\"\"\"作为{expert_info['name']}，请严格遵循以下专业分析框架：\n",
    "\n",
    "{expert_info['description']}\n",
    "\n",
    "专业特长：{expert_info['specialty']}\n",
    "推理风格：{expert_info['reasoning_style']}\n",
    "输出要求：基于稳健性评估的二值判断\n",
    "\n",
    "分析步骤：\n",
    "1. 测试不同假设条件下的结果稳定性\n",
    "2. 进行敏感性分析和边界检验\n",
    "3. 评估结论的稳健程度\n",
    "4. 基于稳健性评估做出明确的二值判断\n",
    "\n",
    "请重点分析结论的可靠性，直接输出是或否（Yes/No）。\\n\\n{base_prompt}\"\"\"\n",
    "    }\n",
    "    \n",
    "    return expert_specific_prompts.get(expert_type, base_prompt)\n",
    "\n",
    "# === MoE 集成函数 ===\n",
    "def aggregate_expert_judgments(expert_results: List[Dict]) -> Dict:\n",
    "    \"\"\"\n",
    "    整合多个专家的判断结果\n",
    "    \"\"\"\n",
    "    if not expert_results:\n",
    "        return {\"label\": 0, \"prob\": 0.5}\n",
    "    \n",
    "    # 简单加权平均\n",
    "    total_prob_yes = 0\n",
    "    total_weight = 0\n",
    "    \n",
    "    for result in expert_results:\n",
    "        weight = result.get(\"confidence\", 1.0)\n",
    "        prob_yes = result[\"prob\"] if result[\"label\"] == 1 else 1 - result[\"prob\"]\n",
    "        total_prob_yes += prob_yes * weight\n",
    "        total_weight += weight\n",
    "    \n",
    "    aggregated_prob_yes = total_prob_yes / total_weight if total_weight > 0 else 0.5\n",
    "    \n",
    "    if aggregated_prob_yes >= 0.5:\n",
    "        return {\"label\": 1, \"prob\": aggregated_prob_yes}\n",
    "    else:\n",
    "        return {\"label\": 0, \"prob\": 1 - aggregated_prob_yes}\n",
    "\n",
    "# === MoE判断函数 ===\n",
    "def run_step_with_moe(base_prompt: str, x1: str, x2: str, question_type: str, method: str = 'frequency') -> Dict:\n",
    "    \"\"\"\n",
    "    使用MoE架构运行单个判断步骤\n",
    "    \"\"\"\n",
    "    # 1. 路由选择专家\n",
    "    selected_experts = expert_router(question_type, x1, x2)\n",
    "    print(f\"为问题 '{question_type}' 选择的专家: {selected_experts}\")\n",
    "    \n",
    "    # 2. 执行专家判断\n",
    "    expert_results = []\n",
    "    for expert in selected_experts:\n",
    "        expert_prompt = create_expert_prompt(base_prompt, expert, x1, x2)\n",
    "        try:\n",
    "            result = llm_judge_with_utils(expert_prompt, x1, x2, method)\n",
    "            result[\"expert\"] = expert\n",
    "            result[\"confidence\"] = 1.0\n",
    "            expert_results.append(result)\n",
    "            print(f\"专家 {expert} 判断完成: label={result['label']}, prob={result['prob']}\")\n",
    "        except Exception as e:\n",
    "            print(f\"专家 {expert} 执行失败: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # 3. 如果没有专家成功，使用默认方法\n",
    "    if not expert_results:\n",
    "        print(\"所有专家执行失败，使用默认方法\")\n",
    "        return llm_judge_with_utils(base_prompt, x1, x2, method)\n",
    "    \n",
    "    # 4. 整合专家意见\n",
    "    final_result = aggregate_expert_judgments(expert_results)\n",
    "    final_result[\"expert_results\"] = expert_results\n",
    "    \n",
    "    print(f\"专家整合结果: label={final_result['label']}, prob={final_result['prob']}\")\n",
    "    return final_result\n",
    "\n",
    "# === 具体判断函数 ===\n",
    "def check_backdoor(x1, x2, all_variables, method='frequency'):\n",
    "    base_prompt = f\"\"\"在因果推断中，考虑以下所有变量：{all_variables}\n",
    "\n",
    "请判断在这些变量中，变量 {x1} 和 {x2} 之间是否存在 back-door path（后门路径）。\n",
    "\n",
    "后门路径是指从 {x1} 到 {x2} 的路径，其中包含指向 {x1} 的箭头，且这条路径没有被阻断。\n",
    "\n",
    "让我们一步步思考，然后直接输出是或否（Yes/No）。\"\"\"\n",
    "    return run_step_with_moe(base_prompt, x1, x2, \"backdoor_path\", method)\n",
    "\n",
    "def check_independence(x1, x2, all_variables, method='frequency'):\n",
    "    base_prompt = f\"\"\"在因果推断中，考虑以下所有变量：{all_variables}\n",
    "\n",
    "请判断变量 {x1} 和 {x2} 是否独立？\n",
    "\n",
    "让我们一步步思考，然后直接输出是或否（Yes/No）。\"\"\"\n",
    "    return run_step_with_moe(base_prompt, x1, x2, \"independence\", method)\n",
    "\n",
    "def check_latent_confounder(x1, x2, all_variables, method='frequency'):\n",
    "    base_prompt = f\"\"\"在因果推断中，考虑以下所有变量：{all_variables}\n",
    "\n",
    "请判断变量 {x1} 和 {x2} 之间是否存在未观察到的潜在混杂因子？\n",
    "\n",
    "让我们一步步思考，然后直接输出是或否（Yes/No）。\"\"\"\n",
    "    return run_step_with_moe(base_prompt, x1, x2, \"latent_confounder\", method)\n",
    "\n",
    "def check_causal_direction(x1, x2, all_variables, method='frequency'):\n",
    "    base_prompt = f\"\"\"在因果推断中，考虑以下所有变量：{all_variables}\n",
    "\n",
    "请判断 {x1} 是否因果导致 {x2}？\n",
    "\n",
    "让我们一步步思考，然后直接输出是或否（Yes/No）。\"\"\"\n",
    "    return run_step_with_moe(base_prompt, x1, x2, \"causal_direction\", method)\n",
    "\n",
    "# === 完整的树查询函数 ===\n",
    "def tree_query(x1, x2, all_variables, method='frequency'):\n",
    "    \"\"\"\n",
    "    基于树状逻辑的因果方向查询器（完整版）\n",
    "    \"\"\"\n",
    "    log = []\n",
    "\n",
    "    # Step 1: 是否存在 backdoor path?\n",
    "    print(\"=== Step 1: 检查后门路径 ===\")\n",
    "    res_backdoor = check_backdoor(x1, x2, all_variables, method)\n",
    "    log.append((\"backdoor_path\", res_backdoor))\n",
    "\n",
    "    if res_backdoor[\"label\"] == 1:\n",
    "        print(\"存在后门路径，进入阻断后分析路径\")\n",
    "        # Step 2: 检查独立性（阻断后）\n",
    "        print(\"=== Step 2: 检查阻断后独立性 ===\")\n",
    "        base_prompt = f\"\"\"在因果推断中，考虑以下所有变量：{all_variables}\n",
    "\n",
    "如果阻断了 {x1} 和 {x2} 之间的所有 back-door path，那么 {x1} 与 {x2} 是否条件独立？\n",
    "\n",
    "让我们一步步思考，然后直接输出是或否（Yes/No）。\"\"\"\n",
    "        res_ind = run_step_with_moe(base_prompt, x1, x2, \"independence\", method)\n",
    "        log.append((\"independent_after_block\", res_ind))\n",
    "        if res_ind[\"label\"] == 1:\n",
    "            return {\"relation\": \"independent\", \"confidence\": res_ind[\"prob\"], \"log\": log}\n",
    "\n",
    "        # Step 3: 是否存在潜在混杂因子（阻断后）？\n",
    "        print(\"=== Step 3: 检查阻断后潜在混杂因子 ===\")\n",
    "        base_prompt = f\"\"\"在因果推断中，考虑以下所有变量：{all_variables}\n",
    "\n",
    "阻断了 {x1} 和 {x2} 之间的所有 back-door path 后，是否仍然存在未观察到的潜在混杂因子同时影响 {x1} 和 {x2}？\n",
    "\n",
    "让我们一步步思考，然后直接输出是或否（Yes/No）。\"\"\"\n",
    "        res_latent = run_step_with_moe(base_prompt, x1, x2, \"latent_confounder\", method)\n",
    "        log.append((\"latent_confounder_after_block\", res_latent))\n",
    "        if res_latent[\"label\"] == 1:\n",
    "            return {\"relation\": \"x<->y\", \"confidence\": res_latent[\"prob\"], \"log\": log}\n",
    "\n",
    "        # Step 4: 判断方向 (x→y?)\n",
    "        print(\"=== Step 4: 判断阻断后因果方向 ===\")\n",
    "        base_prompt = f\"\"\"在因果推断中，考虑以下所有变量：{all_variables}\n",
    "\n",
    "阻断了 {x1} 和 {x2} 之间的所有 back-door path 后，请判断 {x1} 是否因果导致 {x2}？\n",
    "\n",
    "让我们一步步思考，然后直接输出是或否（Yes/No）。\"\"\"\n",
    "        res_dir = run_step_with_moe(base_prompt, x1, x2, \"causal_direction\", method)\n",
    "        log.append((\"x->y_after_block\", res_dir))\n",
    "        if res_dir[\"label\"] == 1:\n",
    "            return {\"relation\": \"x->y\", \"confidence\": res_dir[\"prob\"], \"log\": log}\n",
    "        else:\n",
    "            return {\"relation\": \"y->x\", \"confidence\": res_dir[\"prob\"], \"log\": log}\n",
    "\n",
    "    else:\n",
    "        print(\"不存在后门路径，进入直接分析路径\")\n",
    "        # 不存在 backdoor path\n",
    "        res_ind = check_independence(x1, x2, all_variables, method)\n",
    "        log.append((\"independent_no_backdoor\", res_ind))\n",
    "        if res_ind[\"label\"] == 1:\n",
    "            return {\"relation\": \"independent\", \"confidence\": res_ind[\"prob\"], \"log\": log}\n",
    "\n",
    "        res_latent = check_latent_confounder(x1, x2, all_variables, method)\n",
    "        log.append((\"latent_confounder_no_backdoor\", res_latent))\n",
    "        if res_latent[\"label\"] == 1:\n",
    "            return {\"relation\": \"x<->y\", \"confidence\": res_latent[\"prob\"], \"log\": log}\n",
    "\n",
    "        res_dir = check_causal_direction(x1, x2, all_variables, method)\n",
    "        log.append((\"x->y_no_backdoor\", res_dir))\n",
    "        if res_dir[\"label\"] == 1:\n",
    "            return {\"relation\": \"x->y\", \"confidence\": res_dir[\"prob\"], \"log\": log}\n",
    "        else:\n",
    "            return {\"relation\": \"y->x\", \"confidence\": res_dir[\"prob\"], \"log\": log}\n",
    "\n",
    "# === 使用示例 ===\n",
    "if __name__ == \"__main__\":\n",
    "    # 定义完整的变量集合\n",
    "    all_variables = [\"冰淇淋销量\", \"溺水人数\", \"温度\"]\n",
    "    \n",
    "    print(\"开始因果推断分析...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    result = tree_query(\"冰淇淋销量\", \"溺水人数\", all_variables, method='frequency')\n",
    "    \n",
    "    print(\"\\n=== 最终结果 ===\")\n",
    "    print(f\"变量关系: {result['relation']}\")\n",
    "    print(f\"总体置信度: {result['confidence']:.4f}\")\n",
    "    print(\"\\n=== 详细执行日志 ===\")\n",
    "    \n",
    "    for step_name, step_result in result[\"log\"]:\n",
    "        print(f\"\\n{step_name}:\")\n",
    "        print(f\"  判断: {'是' if step_result['label'] == 1 else '否'}\")\n",
    "        print(f\"  置信度: {step_result['prob']:.4f}\")\n",
    "        if \"expert_results\" in step_result:\n",
    "            print(f\"  专家详情:\")\n",
    "            for expert_result in step_result[\"expert_results\"]:\n",
    "                print(f\"    - {expert_result['expert']}: {'Yes' if expert_result['label'] == 1 else 'No'} (prob={expert_result['prob']:.4f})\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1beafbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def compute_all_causal_relations(variables, method='probability'):\n",
    "    \"\"\"\n",
    "    计算图中每两个变量之间的因果关系，使用tree_query函数。\n",
    "    \n",
    "    输出:\n",
    "        {\n",
    "            (x1, x2): {\n",
    "                'relation': 'x->y' | 'y->x' | 'x<->y' | 'independent',\n",
    "                'confidence': float,\n",
    "                'log': [(step_name, {'label': int, 'prob': float}), ...]\n",
    "            },\n",
    "            ...\n",
    "        }\n",
    "    \"\"\"\n",
    "    all_relations = {}\n",
    "\n",
    "    # 生成所有变量的组合 C(n, 2)\n",
    "    for x1, x2 in combinations(variables, 2):\n",
    "        # 进行 tree_query\n",
    "        result = tree_query(x1, x2, method)\n",
    "        \n",
    "        # 存储结果\n",
    "        all_relations[(x1, x2)] = result\n",
    "\n",
    "    return all_relations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "898045c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Step 1: 检查后门路径 ===\n",
      "12-09 17:14:48 [INFO] llm_utils.online_client - Online LLM client initialized: Qwen3-Next-80B-A3B-Thinking\n",
      "门诊agent原始响应: graph_theory, domain_knowledge, statistical\n",
      "门诊agent推荐: ['graph_theory', 'domain_knowledge', 'statistical']\n",
      "为问题 'backdoor_path' 选择的专家: ['graph_theory', 'domain_knowledge', 'statistical']\n",
      "专家 graph_theory 判断完成: label=0, prob=1.0\n",
      "专家 domain_knowledge 判断完成: label=1, prob=1.0\n",
      "专家 statistical 判断完成: label=1, prob=1.0\n",
      "专家整合结果: label=1, prob=0.6666666666666666\n",
      "存在后门路径，进入阻断后分析路径\n",
      "=== Step 2: 检查阻断后独立性 ===\n",
      "12-09 17:16:02 [INFO] llm_utils.online_client - Online LLM client initialized: Qwen3-Next-80B-A3B-Thinking\n",
      "门诊agent原始响应: statistical, graph_theory, domain_knowledge\n",
      "门诊agent推荐: ['statistical', 'graph_theory', 'domain_knowledge']\n",
      "为问题 'independence' 选择的专家: ['statistical', 'graph_theory', 'domain_knowledge']\n",
      "专家 statistical 判断完成: label=0, prob=1.0\n",
      "专家 graph_theory 判断完成: label=0, prob=1.0\n",
      "专家 domain_knowledge 判断完成: label=0, prob=1.0\n",
      "专家整合结果: label=0, prob=1.0\n",
      "=== Step 3: 检查阻断后潜在混杂因子 ===\n",
      "12-09 17:17:43 [INFO] llm_utils.online_client - Online LLM client initialized: Qwen3-Next-80B-A3B-Thinking\n",
      "门诊agent原始响应: domain_knowledge, graph_theory, statistical\n",
      "门诊agent推荐: ['domain_knowledge', 'graph_theory', 'statistical']\n",
      "为问题 'latent_confounder' 选择的专家: ['domain_knowledge', 'graph_theory', 'statistical']\n",
      "专家 domain_knowledge 判断完成: label=0, prob=1.0\n",
      "专家 graph_theory 判断完成: label=0, prob=1.0\n",
      "专家 statistical 判断完成: label=0, prob=1.0\n",
      "专家整合结果: label=0, prob=1.0\n",
      "=== Step 4: 判断阻断后因果方向 ===\n",
      "12-09 17:19:13 [INFO] llm_utils.online_client - Online LLM client initialized: Qwen3-Next-80B-A3B-Thinking\n",
      "门诊agent原始响应: domain_knowledge, temporal_dynamics, counterfactual\n",
      "门诊agent推荐: ['domain_knowledge', 'temporal_dynamics', 'counterfactual']\n",
      "为问题 'causal_direction' 选择的专家: ['domain_knowledge', 'temporal_dynamics', 'counterfactual']\n",
      "专家 domain_knowledge 判断完成: label=1, prob=1.0\n",
      "专家 temporal_dynamics 判断完成: label=1, prob=1.0\n",
      "专家 counterfactual 判断完成: label=1, prob=1.0\n",
      "专家整合结果: label=1, prob=1.0\n",
      "=== Step 1: 检查后门路径 ===\n",
      "12-09 17:20:02 [INFO] llm_utils.online_client - Online LLM client initialized: Qwen3-Next-80B-A3B-Thinking\n",
      "门诊agent原始响应: graph_theory,domain_knowledge,statistical\n",
      "门诊agent推荐: ['graph_theory', 'domain_knowledge', 'statistical']\n",
      "为问题 'backdoor_path' 选择的专家: ['graph_theory', 'domain_knowledge', 'statistical']\n",
      "专家 graph_theory 判断完成: label=1, prob=1.0\n",
      "专家 domain_knowledge 判断完成: label=1, prob=1.0\n",
      "专家 statistical 判断完成: label=1, prob=1.0\n",
      "专家整合结果: label=1, prob=1.0\n",
      "存在后门路径，进入阻断后分析路径\n",
      "=== Step 2: 检查阻断后独立性 ===\n",
      "12-09 17:22:14 [INFO] llm_utils.online_client - Online LLM client initialized: Qwen3-Next-80B-A3B-Thinking\n",
      "门诊agent原始响应: statistical,domain_knowledge,graph_theory\n",
      "门诊agent推荐: ['statistical', 'domain_knowledge', 'graph_theory']\n",
      "为问题 'independence' 选择的专家: ['statistical', 'domain_knowledge', 'graph_theory']\n",
      "专家 statistical 判断完成: label=0, prob=1.0\n",
      "专家 domain_knowledge 判断完成: label=0, prob=1.0\n",
      "专家 graph_theory 判断完成: label=1, prob=1.0\n",
      "专家整合结果: label=0, prob=0.6666666666666667\n",
      "=== Step 3: 检查阻断后潜在混杂因子 ===\n",
      "12-09 17:24:34 [INFO] llm_utils.online_client - Online LLM client initialized: Qwen3-Next-80B-A3B-Thinking\n",
      "门诊agent原始响应: graph_theory, domain_knowledge, robustness_analysis\n",
      "门诊agent推荐: ['graph_theory', 'domain_knowledge', 'robustness_analysis']\n",
      "为问题 'latent_confounder' 选择的专家: ['graph_theory', 'domain_knowledge', 'robustness_analysis']\n",
      "专家 graph_theory 判断完成: label=1, prob=1.0\n",
      "专家 domain_knowledge 判断完成: label=0, prob=1.0\n",
      "专家 robustness_analysis 判断完成: label=0, prob=1.0\n",
      "专家整合结果: label=0, prob=0.6666666666666667\n",
      "=== Step 4: 判断阻断后因果方向 ===\n",
      "12-09 17:26:05 [INFO] llm_utils.online_client - Online LLM client initialized: Qwen3-Next-80B-A3B-Thinking\n",
      "门诊agent原始响应: domain_knowledge, temporal_dynamics, mechanism_modeling\n",
      "门诊agent推荐: ['domain_knowledge', 'temporal_dynamics', 'mechanism_modeling']\n",
      "为问题 'causal_direction' 选择的专家: ['domain_knowledge', 'temporal_dynamics', 'mechanism_modeling']\n",
      "专家 domain_knowledge 判断完成: label=1, prob=1.0\n",
      "专家 temporal_dynamics 判断完成: label=1, prob=1.0\n",
      "专家 mechanism_modeling 判断完成: label=1, prob=1.0\n",
      "专家整合结果: label=1, prob=1.0\n",
      "=== Step 1: 检查后门路径 ===\n",
      "12-09 17:27:23 [INFO] llm_utils.online_client - Online LLM client initialized: Qwen3-Next-80B-A3B-Thinking\n",
      "门诊agent原始响应: graph_theory,domain_knowledge,statistical\n",
      "门诊agent推荐: ['graph_theory', 'domain_knowledge', 'statistical']\n",
      "为问题 'backdoor_path' 选择的专家: ['graph_theory', 'domain_knowledge', 'statistical']\n",
      "专家 graph_theory 判断完成: label=1, prob=1.0\n",
      "专家 domain_knowledge 判断完成: label=1, prob=1.0\n",
      "专家 statistical 判断完成: label=1, prob=1.0\n",
      "专家整合结果: label=1, prob=1.0\n",
      "存在后门路径，进入阻断后分析路径\n",
      "=== Step 2: 检查阻断后独立性 ===\n",
      "12-09 17:28:03 [INFO] llm_utils.online_client - Online LLM client initialized: Qwen3-Next-80B-A3B-Thinking\n",
      "门诊agent原始响应: domain_knowledge, statistical, graph_theory\n",
      "门诊agent推荐: ['domain_knowledge', 'statistical', 'graph_theory']\n",
      "为问题 'independence' 选择的专家: ['domain_knowledge', 'statistical', 'graph_theory']\n",
      "专家 domain_knowledge 判断完成: label=1, prob=1.0\n",
      "专家 statistical 判断完成: label=1, prob=1.0\n",
      "专家 graph_theory 判断完成: label=1, prob=1.0\n",
      "专家整合结果: label=1, prob=1.0\n",
      "Relation between 气温 and 冰淇淋销量: x->y (Confidence: 1.0)\n",
      "Relation between 气温 and 溺水人数: x->y (Confidence: 1.0)\n",
      "Relation between 冰淇淋销量 and 溺水人数: independent (Confidence: 1.0)\n"
     ]
    }
   ],
   "source": [
    "variables = ['气温', '冰淇淋销量', '溺水人数']\n",
    "relations = compute_all_causal_relations(variables)\n",
    "\n",
    "for (x1, x2), relation in relations.items():\n",
    "    print(f\"Relation between {x1} and {x2}: {relation['relation']} (Confidence: {relation['confidence']})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
